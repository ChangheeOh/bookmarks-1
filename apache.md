Apache
======
* [apache bigdata europe](http://events.linuxfoundation.org/events/apache-big-data-europe/program/schedule)
* [Apache 프로젝트 만들기(1)](http://www.popit.kr/apache-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EB%A7%8C%EB%93%A4%EA%B8%B0-1/)
* [Apache 프로젝트 만들기(2)](http://www.popit.kr/apache-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EB%A7%8C%EB%93%A4%EA%B8%B02/)
* [Projects by category](https://projects.apache.org/projects.html?category)

# Airflow
* [Integrating Apache Airflow and Databricks: Building ETL pipelines with Apache Spark](https://databricks.com/blog/2016/12/08/integrating-apache-airflow-databricks-building-etl-pipelines-apache-spark.html)
  * Apache Airflow에서 REST API를 사용하여 Databricks 클러스터를 관리하는 예를 소개
* [데이타 워크플로우 관리를 위한 Apache Airflow #1 - 소개](http://bcho.tistory.com/1184)
* [Airflow Tutorial for Data Pipelines](https://blog.godatadriven.com/practical-airflow-tutorial)
  * Apache Airflow를 시작할 때 참고할만한 튜토리얼
* [**Apache Airflow를 이용한 데이터 워크플로우 자동화**](http://whitechoi.tistory.com/50)
* [ETL best practices with Airflow documentation site](https://gtoonstra.github.io/etl-with-airflow/)
* [Integrating Apache Airflow with Apache Ambari](https://medium.com/@mykolamykhalov/integrating-apache-airflow-with-apache-ambari-ccab2c90173)
* [Modern Data Pipelines with Apache Airflow (Momentum 2018 talk)](http://blog.tedmiston.com/momentum-2018-airflow-talk/) Apache Airflow의 개념, 몇 가지 예제
* [When Airflow isn’t fast enough: Distributed orchestration of multiple small workloads with Celery](https://medium.com/@manuelmourato25/when-airflow-isnt-fast-enough-distributed-orchestration-of-multiple-small-workloads-with-celery-afb3daebe611)
* [Apache Airflow in the Cloud: Programmatically orchestrating workloads w/ Py - Satyasheel, Kaxil Naik](https://www.youtube.com/watch?v=ZZ5okeRGRB8)
* [Advanced Data Engineering Patterns with Apache Airflow](https://prezi.com/p/adxlaplcwzho/advanced-data-engineering-patterns-with-apache-airflow/) AirBnB 데이터 엔지니어링팀의 A/B test, AutoDAG, Engagement & Growth metrics, Scaling 등을 구현하는 Apache Airflow 구축 방법 소개
* [How to start automating your data pipelines with Airflow](https://blog.insightdatascience.com/airflow-101-start-automating-your-batch-workflows-with-ease-8e7d35387f94)
* [Building a Big Data Pipeline With Airflow, Spark and Zeppelin](https://medium.com/swlh/building-a-big-data-pipeline-with-airflow-spark-and-zeppelin-843f31ef220c)
* [Airflow: Lesser Known Tips, Tricks, and Best Practises](https://medium.com/datareply/airflow-lesser-known-tips-tricks-and-best-practises-cf4d4a90f8f)
* [Airflow를 이용한 데이터 Workflow 관리](https://www.slideshare.net/YoungHeonKim1/airflow-workflow)
* [우분투(Ubuntu)에 아파치 에어플로우 (Apache Airflow) 설치](https://jungwoon.github.io/airflow/2019/02/26/Airflow/)
* [실무에 바로 사용하는 Airflow 2.0 설치](https://burning-dba.tistory.com/127)
* [docker-compose로 Airflow 한방에 설치하기](https://jybaek.tistory.com/922)
* [jwon.org/tag/airflow](https://jwon.org/tag/airflow/)
* [Getting started with Apache Airflow](https://towardsdatascience.com/getting-started-with-apache-airflow-df1aa77d7b1b)
* [Data pipelines, Luigi, Airflow: everything you need to know](https://towardsdatascience.com/data-pipelines-luigi-airflow-everything-you-need-to-know-18dc741449b7)
* [Cloud Composer 에서 Airflow Web Server REST API 로 외부에서 DAG 트리거하기](https://chang12.github.io/composer-trigger-dag/)
* [입 개발 airflow 의 schedule_interval 에 대해서](https://charsyam.wordpress.com/2020/04/16/%EC%9E%85-%EA%B0%9C%EB%B0%9C-airflow-%EC%9D%98-schedule_interval-%EC%97%90-%EB%8C%80%ED%95%B4%EC%84%9C/)
* [AWS EMR과 Airflow를 이용한 Batch Data Processing | by Min Jo | 101-devs | Aug, 2020 | Medium](https://medium.com/class101-dev/aws-emr%EA%B3%BC-airflow%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-batch-data-processing-a100fc2f4f10)
* [CLASS101에서 Airflow와 Amazon EMR을 활용한 ETL 파이프라인 구축 - 조민구(CLASS101) :: 제32회 AWSKRUG DataScience모임 - YouTube](https://www.youtube.com/watch?v=ZhW0exu-woU)
* [Introducing Airflow 2.0 | Astronomer](https://www.astronomer.io/blog/introducing-airflow-2-0)
* [Airflow 실패여부 slack알람으로 받기 (python)](https://burning-dba.tistory.com/102)
* [airflow CPU가 높게 점유되는 현상](https://burning-dba.tistory.com/111)
* [airflow dag의 task를 실행하고 동작하지 않는 현상](https://burning-dba.tistory.com/117)
* [Airflow의 execution_date에 대하여 - Nephtyw’S Programming Stash](https://nephtyws.github.io/data/airflow-execution-date/)
* [버킷플레이스 Airflow 도입기 - 오늘의집 블로그](https://www.bucketplace.co.kr/post/2021-04-13-%EB%B2%84%ED%82%B7%ED%94%8C%EB%A0%88%EC%9D%B4%EC%8A%A4-airflow-%EB%8F%84%EC%9E%85%EA%B8%B0/)
* [쏘카 데이터 그룹 - Airflow와 함께한 데이터 환경 구축기(feat. Airflow on Kubernetes) - SOCAR Tech Blog](https://tech.socarcorp.kr/data/2021/06/01/data-engineering-with-airflow.html)
  * 처음에는 Rundeck 이용, Airflow를 사용하기로 하면서 매니지드 서비스인 GCP의 Composer 사용, 회사와 데이터 팀이 커지면서 문제 발생
  * 결국 Kubernetes 위에서 Airflow를 구축해서 운영하기로 결정. Kubernetes 위에서 운영하는 방법을 자세히 설명
* [Hello, Apache Airflow](https://jybaek.tistory.com/921)
* [후기 이미지 자동 검수 모델, 어떻게 서비스할까? | by MUSINSA tech | Medium | MUSINSA tech](https://medium.com/musinsa-tech/imageclassification-d5b06f55b9f5)
* [airflow 파라미터 튜닝](https://jybaek.tistory.com/923)
* [나만의 Airflow 클러스터 만들기 (feat. k3d)](https://www.humphreyahn.dev/blog/my-own-airflow-cluster)
* [Apache Airflow와 Amazon SageMaker Feature Store 연동하기 | by Sungin Lee | Cloud Villains | Sep, 2021 | Medium](https://medium.com/ctc-mzc/apache-airflow%EC%99%80-amazon-sagemaker-feature-store-%EC%97%B0%EB%8F%99%ED%95%98%EA%B8%B0-6fe2b75ea5d4)
* [Misconfigured, old Airflow instances leak Slack, AWS credentials | ZDNet](https://www.zdnet.com/article/misconfigured-airflow-instances-leak-slack-aws-credentials/)
* [ETL Pipelines with Airflow: the Good, the Bad and the Ugly | Airbyte](https://airbyte.io/blog/airflow-etl-pipelines)

# Ambari
* [3 GREAT REASONS TO TRY APACHE HIVE VIEW 2.0](https://hortonworks.com/blog/3-great-reasons-to-try-hive-view-2-0/)
  * Apache Ambari에서 Apache Hive 2.5와 상호 작용할 수 잇는 새로운 기능을 소개
  * Optimizer가 사용하는 테이블과 컬럼 통계를 보고 연산 가능, Explain pland 시각화 포함
* [WHY SHOULD YOU CARE ABOUT AMBARI 2.5?](https://hortonworks.com/blog/ambari-2-5/)
  * Apache Ampari 2.5 공개. 서비스 자동 재시작, 로그 로테이션/로그 검색, 개선된 구성 관리와 새로운 모니터링 기능 등이 포함
* [How to upgrade Apache Ambari 2.6.2 to Apache Ambari 2.7.3](https://www.youtube.com/watch?v=BJfF5jMfAqk)

# Apex
* [Apex](http://apex.apache.org/) 스트림 및 배치 프로세스 엔진
* [Real-time Stream Processing using Apache Apex](http://www.slideshare.net/ApacheApex/realtime-stream-processing-using-apache-apex)
* [Throughput, Latency, and Yahoo! Performance Benchmarks. Is there a winner? - See more at: https://www.datatorrent.com/blog/throughput-latency-and-yahoo](https://www.datatorrent.com/blog/throughput-latency-and-yahoo/)
* [SQL on Apache Apex](https://www.datatorrent.com/blog/sql-apache-apex)
* [Writing to Apache Kudu from Apache Apex](http://www.atrato.io/blog/2017/05/28/apex-kudu-output/)
  * Apache Apex를 사용하여 Apache Kafka에서 Apache Kudu로 데이터를 쓰는 방법

# Arrow
* [Arrow](http://arrow.apache.org/)
* [Apache Arrow - Powering Columnar In-Memory Analytics - Arrow is a set of technologies that enable big-data systems to process and move data fast](https://github.com/apache/arrow)
* [Why pandas users should be excited about Apache Arrow](http://wesmckinney.com/blog/pandas-and-apache-arrow/)
* [Feather: A Fast On-Disk Format for Data Frames for R and Python, powered by Apache Arrow](http://blog.cloudera.com/blog/2016/03/feather-a-fast-on-disk-format-for-data-frames-for-r-and-python-powered-by-apache-arrow/)
* [Introducing Apache Arrow: A Fast, Interoperable In-Memory Columnar Data Structure Standard](http://blog.cloudera.com/blog/2016/02/introducing-apache-arrow-a-fast-interoperable-in-memory-columnar-data-structure-standard/)
* [Improving Python and Spark Performance and Interoperability with Apache Arrow](https://www.slideshare.net/julienledem/improving-python-and-spark-performance-and-interoperability-with-apache-arrow)
  * Apache Arrow 프로젝트는 cross-language columnar in-memory alanytics를 구현
  * 대부분의 개발자는 Arrow를 직접 다루지 않지만 PySpark와 같은 여러 가지 작업을 빠르게 처리 가능(하다고 주장)
  * 이 프레젠테이션은 Arrow가 무엇인지, 그리고 그것이 어떻게 속도 향상을 이룰 수 있는지 소개
* [Apache Arrow (Python)](https://arrow.apache.org/docs/python/)
  * [Reading and Writing the Apache Parquet Format](https://arrow.apache.org/docs/python/parquet.html#reading-and-writing-the-apache-parquet-format)
* [Wes McKinney: Ursa Labs and Apache Arrow in 2019 | PyData Miami 2019](https://www.youtube.com/watch?v=7HiwzHWiF20)
* [Apache Arrow and Java: Lightning Speed Big Data Transfer](https://www.infoq.com/articles/apache-arrow-java/)
* [Apache Arrow: Read DataFrame With Zero Memory | Towards Data Science](https://towardsdatascience.com/apache-arrow-read-dataframe-with-zero-memory-69634092b1a)

# Atlas
* [Atlas](https://atlas.apache.org/) 데이터 거버넌스, 표준, 계보 관리 플랫폼
* [Apache Atlas — Using the v2 Rest API](https://medium.com/hashmapinc/apache-atlas-using-the-v2-rest-api-6f9be1c256ae) Atlas의 Rest API를 사용하여 데이터를 기록하는 방법 소개

# Beam
* Former [DataFlow](https://wiki.apache.org/incubator/DataflowProposal)
* [The Beam Model : Streams & Tables](https://docs.google.com/document/d/1u-4o_0uj8uKa2SVNPBNxIKfvcJ4t66ecCoU1M2yVoDA/mobilebasic)
  * 스트림 및 테이블을 기반으로 작성된 Apache Beam 모델에 대한 내용
* [bcho.tistory.com/search/dataflow](http://bcho.tistory.com/search/dataflow)
* [구글 데이타 스트리밍 데이타 분석 플랫폼 dataflow - #1 소개](http://bcho.tistory.com/1123)
* [데이타 스트리밍 분석 플랫폼 Dataflow 개념 잡기 #1/2](http://bcho.tistory.com/1122)
* [데이타 스트리밍 분석 플랫폼 Dataflow 개념 잡기 #2/2](http://bcho.tistory.com/1124)
* [GOOGLE DATA FLOW - Google의 Data Flow 개념 및 프로그래밍 방법](https://jungwoon.github.io/jungwoon.github.io/Google-Data-Flow/)
* [데이타 플로우 #4 개발환경 설정하기](http://bcho.tistory.com/1128)
* [데이타 플로우 #5 프로그래밍 모델의 이해](http://bcho.tistory.com/1129)
* [Face recognition Image Cropping and Filtering notebook](https://github.com/bwcho75/facerecognition/blob/master/Preprocess%2Bface%2Brecognition%2Bdata%2Band%2Bgenerate%2Btraining%2Bdata.ipynb)
  * Apache Beam 기반의 전처리 코드
* [Comparing the Dataflow/Beam and Spark Programming Models](https://cloud.google.com/blog/big-data/2016/02/comparing-the-dataflowbeam-and-spark-programming-models#closeImage)
* [Type safe BigQuery in Apache Beam with Spotify’s Scio](https://medium.com/swlh/type-safe-bigquery-in-apache-beam-with-spotifys-scio-c519fd44553d)

# BookKeeper
* [Apache BookKeeper: A High Performance and Low Latency Storage Service](https://www.slideshare.net/hustlmsp/apache-bookkeeper-a-high-performance-and-low-latency-storage-service)

# Brooklyn
* [Brooklyn](https://brooklyn.apache.org/)

# Camel
* [Camel](https://github.com/apache/camel)
* [Apache Camel 소개](https://medium.com/@OutOfBedlam/apache-camel-%EC%86%8C%EA%B0%9C-1b20e6e12a93)
* [Streaming in the Cloud With Camel and Strimzi](http://blog.joshdreagan.com/2019/05/30/streaming_in_the_cloud_with_camel_and_strimzi/)
* [How Apache Camel simplified our process integrations](https://medium.com/trendyol-tech/how-apache-camel-simplified-our-process-integrations-9e17d0251650)

# Commons
* [Commons](https://commons.apache.org/)

# Cordova
* [Apache Cordova: after 10 months, I won't be using it anymore](http://geekcoder.org/apache-cordova-after-10-months-i-wont-using-it-anymore/)
* [Cordova 환경 구성 & Git Ignore 설정](http://brantiffy.axisj.com/archives/377)
* [ionic cordova emulate 실행 시 Cannot read property 'replace' of undefined 에러 해결하기](http://www.haruair.com/blog/3962)

# Crunch
* [Crunch](https://crunch.apache.org/)

# Drill
* [Drill](http://drill.apache.org/)
* [Apache Drill SQL Query Optimization | Whiteboard Walkthrough](https://www.mapr.com/blog/apache-drill-sql-query-optimization-whiteboard-walkthrough)
* [A Gentle introduction to Apache Drill](https://medium.com/a-tale-of-2-from-data-to-information/apache-drill-101-391c5eb801c8)

# Druid
* [Druid](http://incubator.apache.org/projects/druid.html)
* [druid.io](http://druid.io/)
* [임플라이, 드루이드 기반 오픈소스 분석 플랫폼 공개](http://www.bloter.net/archives/241499)
* [Imply - Exploratory Analytics Powered By Druid](http://imply.io/)
* [Druid is a high-performance, column-oriented, distributed data store](http://druid.io/)
* [An Introduction to Druid](http://sssslide.com/speakerdeck.com/druidio/an-introduction-to-druid)
* [Aggregated queries with Druid on terrabytes and petabytes of data](http://www.slideshare.net/RostislavPashuto/aggregated-queries-with-druid-on-terrabytes-and-petabytes-of-data)
* [Combining Druid and Spark: Interactive and Flexible Analytics at Scale](https://www.linkedin.com/pulse/combining-druid-spark-interactive-flexible-analytics-scale-butani)
* Time series OLAP
  * [Druid 입문(1)](http://www.popit.kr/time-series-olap-druid-%EC%9E%85%EB%AC%B8/)
  * [Druid 실시간 수집(2)](http://www.popit.kr/time-series-olap-druid-%EC%8B%A4%EC%8B%9C%EA%B0%84-%EC%88%98%EC%A7%912/)
  * [Druid Batch Ingestion(3)](http://www.popit.kr/time-series-olap-druid-batch-ingestion3/)
  * [Druid Segment(4)](http://www.popit.kr/time-series-olap-druid-segment/)
  * [Glue Architecture(5)](http://www.popit.kr/time-series-olap-druid-glue-architecture/)
  * [Druid Trouble Shooting(6)](https://www.popit.kr/time-series-olap-druid-trouble-shooting/)
* [Scalable Real-time analytics using Druid](http://www.slideshare.net/HadoopSummit/scalable-realtime-analytics-using-druid)
* [Druid 성능 엿보기. Spark이랑 같이 보자](http://www.popit.kr/druid-spark-performance/)
* [JDBC를 통한 하둡 적재, 알면 도움되는 삽질 이야기 1편](http://www.popit.kr/spadework1/)
* [Hive 와 Druid로 울트라-빠른 OLAP 분석하기](http://www.popit.kr/ultra-fast_olap_druid/)
* [벤치마크 Apache Hive와 Druid를 통한 sub-second 분석 -2편](http://www.popit.kr/ultra-fast_olap_druid2/)
* [Ultra-Fast OLAP Analytics With Apache Hive and Druid (Part 1)](https://dzone.com/articles/ultra-fast-olap-analytics-with-apache-hive-and-dru)
* [Ultra-Fast OLAP Analytics With Apache Hive and Druid (Part 2)](https://dzone.com/articles/ultra-fast-olap-analytics-with-apache-hive-and-dru-1)
* [4th Druid Meetup 참석 후기](http://www.popit.kr/4th-druid-meetup-%EC%B0%B8%EC%84%9D-%ED%9B%84%EA%B8%B0/)
* [Comparison of the Open Source OLAP Systems for Big Data: ClickHouse, Druid and Pinot](https://medium.com/@leventov/comparison-of-the-open-source-olap-systems-for-big-data-clickhouse-druid-and-pinot-8e042a5ed1c7)
  * Open Source 분산 스토리지 엔진인 ClickHouse, Druid, Pinot을 비교
  * 시스템 간의 유사성(예: 저장 및 인덱스), 성능 특성, 데이터 처리, 데이터 복제 및 쿼리 실행의 유사성과 차이점 설명
* [Web analytics at scale with Druid at naver.com](https://www.slideshare.net/JasonJungsuHEO/web-analytics-at-scale-with-druid-at-navercom)
* [An introduction to Druid, your Interactive Analytics at (big) Scale](https://blog.zysset.me/introduction-to-druid/)
* [How Druid enables analytics at Airbnb](https://medium.com/airbnb-engineering/druid-airbnb-data-platform-601c312f2a4c)
  * Airbnb에서 분석을 위해 Druid를 사용한 경험담 소개
  * Druid를 통해 다른 빅데이터 시스템 보완 방법, Spark Streaming으로 데이터 수집 방법, Presto 통합 방법, 모니터링 그리고 문제점 및 향후 개선 사항 설명
* [Realtime Data in Apache Druid — Choosing the Right Strategy](https://towardsdatascience.com/realtime-data-in-apache-druid-choosing-the-right-strategy-cd1594dc66e0)
* [How Netflix uses Druid for Real-time Insights to Ensure a High-Quality Experience](https://netflixtechblog.com/how-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06)
* [What Makes Apache Druid Great for Realtime Analytics?](https://codeburst.io/what-makes-apache-druid-great-for-realtime-analytics-61f817ee5ff6)
* [입개발 Druid에서 transform 시 알아야 할 팁. | Charsyam's Blog](https://charsyam.wordpress.com/2020/07/01/%ec%9e%85%ea%b0%9c%eb%b0%9c-druid%ec%97%90%ec%84%9c-transform-%ec%8b%9c-%ec%95%8c%ec%95%84%ec%95%bc-%ed%95%a0-%ed%8c%81/)
* [metatron.app](https://metatron.app/) Self-service Solution for Big Data Discovery. All-in-one analytics from easy data preparation to fast visualization
  * [github.com/metatron-app](https://github.com/metatron-app)

# Eagle
* [Apache Eagle](https://blogs.apache.org/foundation/entry/the-apache-software-foundation-announces1)

# Falcon
* [Falcon - Simplifying Managing Data Jobs on Hadoop](http://www.slideshare.net/Hadoop_Summit/apache-falcon-simplifying-managing-data-jobs-on-hadoop)

# Flink
* [Flink](https://flink.apache.org/)
* [Apache Flink Training](http://dataartisans.github.io/flink-training/)
* [Juggling with Bits and Bytes](http://flink.apache.org/news/2015/05/11/Juggling-with-Bits-and-Bytes.html)
* [스사모 테크톡 - Apache Flink 둘러보기](http://www.slideshare.net/sangwookimme/apache-flink-48832827)
* [Off-heap Memory in Apache Flink and the curious JIT compiler](http://flink.apache.org/news/2015/09/16/off-heap-memory.html)
* [Stream Processing with Apache Flink](http://blog.brakmic.com/stream-processing-with-apache-flink/)
* [High-throughput, low-latency, and exactly-once stream processing with Apache Flink](http://data-artisans.com/high-throughput-low-latency-and-exactly-once-stream-processing-with-apache-flink/)
* [Continuous Processing with Apache Flink - Strata London 2016](http://www.slideshare.net/stephanewen1/continuous-processing-with-apache-flink-strata-london-2016)
* Introduction to Flink Streaming
  * [Part 1 : WordCount](http://blog.madhukaraphatak.com/introduction-to-flink-streaming-part-1/)
  * [Part 2 : Discretization of Stream using Window API](http://blog.madhukaraphatak.com/introduction-to-flink-streaming-part-2/)
  * [Part 3 : Running Streaming Applications in Flink Local Mode](http://blog.madhukaraphatak.com/introduction-to-flink-streaming-part-3/)
  * [Part 4 : Understanding Flink's Advanced Stream Processing using Google Cloud Dataflow](http://blog.madhukaraphatak.com/introduction-to-flink-streaming-part-4/)
  * [Part 5 : Window API in Flink](http://blog.madhukaraphatak.com/introduction-to-flink-streaming-part-5/)
  * [Part 6 : Anatomy of Window API](http://blog.madhukaraphatak.com/introduction-to-flink-streaming-part-6/)
  * [Part 7 : Implementing Session Windows using Custom Trigger](http://blog.madhukaraphatak.com/introduction-to-flink-streaming-part-7/)
  * [Part 8 : Understanding Time in Flink Streaming](http://blog.madhukaraphatak.com/introduction-to-flink-streaming-part-8/)
  * [Part 9 : Event Time in Flink](http://blog.madhukaraphatak.com/introduction-to-flink-streaming-part-9/)
  * [Part 10 : Meetup Talk](http://blog.madhukaraphatak.com/introduction-to-flink-streaming-part-10/)
  * [Introduction to Flink Streaming](https://www.slideshare.net/datamantra/introduction-to-flink-streaming)
  * [Flink Examples](https://github.com/phatak-dev/flink-examples)
* [A Deep Dive into Rescalable State in Apache Flink](http://flink.apache.org/features/2017/07/04/flink-rescalable-state.html)
  * 체크 포인트 기능을 사용하여 작업을 조정 (예 : 병렬 처리를 늘리거나 줄이기)하는 방법에 대해 설명
* [Stream Processing with Apache Flink and DC/OS](https://mesosphere.com/blog/stream-processing-apache-flink/)
  * DC/OS를 사용하여 Mesos에서 Apache Flink 스트리밍 작업을 실행하는 방법에 대해 소개
* [StreamING Machine Learning Models: How ING Adds Fraud Detection Models at Runtime with Apache Flink®](https://data-artisans.com/blog/real-time-fraud-detection-ing-bank-apache-flink)
  * ING 생명이 리스크 분석 엔진으로 Apache Flink를 어떻게 사용하는지 설명
  * Apache Spark, Knime 및 Apache Zeppelin을 일괄 처리 모델로 사용하지만 실시간 구성 요소는 Flink를 사용
* [PREDICTIVE MAINTENANCE WITH APACHE FLINK](https://berlin.flink-forward.org/kb_sessions/predictive-maintenance-with-apache-flink/)
  * Keras로 만든 time-series prediction model을 Flink와 연동한 이야기
  * python deep learning library(tensorflow, keras)를 이용해서 만든 모델을 JVM에서 어떻게 사용하는지
  * Apache Spark에 비해서 Apache Flink가 가지는 장점에는 어떤 것들이 있는지
* [Complex Event Processing with Flink: An Update on the State of Flink CEP](https://data-artisans.com/blog/complex-event-processing-flink-cep-update)
  * Flink는 이벤트 패턴을 감지하는 고급 API를 제공하여 복잡한 이벤트 처리를 지원
  * API에 대한 개요와 온라인 소매 업체의 선적 추적에 대한 예제
* [An Overview of End-to-End Exactly-Once Processing in Apache Flink® (with Apache Kafka, too!)](https://data-artisans.com/blog/end-to-end-exactly-once-processing-apache-flink-apache-kafka)
* [Apache Flink Basic Transformation Example](https://dzone.com/articles/apache-flink-basic-transformation-example) 파일 데이터를 읽어 대문자로 변환한 후 다른 파일에 쓰는 예제
* [Flink Forward San Francisco 2018 Videos and Slides](https://data-artisans.com/flink-forward-san-francisco-2018)
* STREAM ANALYTICS PLATFORM FOR A TELCO
  * Apache Flink와 Flink 기반으로 스트림 처리 시스템 구축을 한 사례 설명
  * 합성 데이터로 시스템을 테스트하는 방법과 ELK를 사용하여 모니터링 하는 방법도 설명
  * [PART 1](http://getindata.com/stream-analytics-platform-telco-part-1/)
  * [PART 2](http://getindata.com/stream-analytics-platform-telco-part-2/)
* [Flink at netflix paypal speaker series](https://www.slideshare.net/mdaxini/flink-at-netflix-paypal-speaker-series-104453588)
  * Netflix의 (수천 대 규모의) 스트림 처리 시스템은 하루 약 4조개 이상(36GB/sec)의 이벤트를 처리
  * 이 시스템은 Apache Flink와 Apache Kafka 기반으로 하는 셀프 서비스 인프라로 구축
  * Flink를 사용하는 이유와 구현과 운영에 대해 설명
* [State TTL for Apache Flink: How to Limit the Lifetime of State](https://data-artisans.com/blog/state-ttl-for-apache-flink-how-to-limit-the-lifetime-of-state) Flink 1.6.0 TTL 지원
* [Flink Forward Berlin 2018: Dongwon Kim - "Real-time driving score service using Flink"](https://www.slideshare.net/FlinkForward/flink-forward-berlin-2018-dongwon-kim-realtime-driving-score-service-using-flink)
  * [Real-time driving score service using Flink](https://data-artisans.com/flink-forward-berlin/resources/real-time-driving-score-service-using-flink)
* [Automatic Apache Flink deployments in Golang](https://medium.com/wbaa/flink-deployer-8c0db4c94fe4)
* [Automating Flink Deployments to Kubernetes](https://data-artisans.com/flink-forward-berlin/resources/automating-flink-deployments-to-kubernetes)
* [Introduction to Apache Flink](https://speakerdeck.com/chiwanpark/introduction-to-apache-flink)
* [Flink or Flunk? Why Ele.me Is Developing a Taste for Apache Flink](https://hackernoon.com/flink-or-flunk-why-ele-me-is-developing-a-taste-for-apache-flink-7d2a74e4d6c0)
  * Alibaba의 Ele.me 팀에서 데이터 스트림 처리 시스템으로 Apache Flink를 도입한 사례
  * Apache Storm, Apache Spark와 비교하여 Flink를 선택한 배경 설명
* [Introduction of apache flink kosscon2018](https://www.slideshare.net/secret/dhQ4aYqD02SQ11)
* [About Flink streaming](https://www.slideshare.net/ssusera7e5ca/about-flink-streaming-126179502)
* [A Brief History of Flink: Tracing the Big Data Engine’s Open-source Development](https://medium.com/@alitech_2017/a-brief-history-of-flink-tracing-the-big-data-engines-open-source-development-87464fd19e0f)
* [Patterns of Streaming Applications](https://www.youtube.com/watch?v=RKIKbMi1H5E)
* [Better to Give and to Receive: Alibaba’s Open-source Contributions to Flink](https://hackernoon.com/better-to-give-and-to-receive-alibabas-open-source-contributions-to-flink-295b3aef1da8)
* [Running Apache Flink on Kubernetes](https://jobs.zalando.com/tech/blog/running-apache-flink-on-kubernetes)
  * 모니터링(prometheus) 연결; flink /opt 안에 있는 prometheus jar 파일을 /lib 에 옮기고 flink-confi.yaml 에 metrics 부분 설정해준후에 job/task pod annotation 에 prometheus.io/port 와 prometheus.io/scrape 만 설정하면 prometheus sd가 잘 수집
* [Berlin 2019](https://berlin-2019.flink-forward.org/conference-program)
* [europe-2019.flink-forward.org/conference-program](https://europe-2019.flink-forward.org/conference-program)
* [Flink Forward Global 2021](https://www.flink-forward.org/global-2021)
* [Apache Flink® SQL Training](https://github.com/ververica/sql-training)
* [Do Flink on Web with FLOW](https://speakerdeck.com/eastcirclek/do-flink-on-web-with-flow)
* [0x90e.github.io/tags/Flink](https://0x90e.github.io/tags/Flink/) 사용자 코드가 어떻게 Graph로 만들어지고 JobManager로 submit 되는지 코드 단위로 설명한 포스트라고 하는데 중국어
* [T map에 Flink 이식하기](https://drive.google.com/file/d/1lJi3Slkj5BcSTfjalL-pj3RpVKbvO70t)
* [**Flink Source 부터 Sink 까지**](https://docs.google.com/presentation/d/1eLJz1HS_4lN-st1TYJYIJyZt6DUZyG1yGrIS8v4cPM0)
* [Deep dive into flink interval join](https://www.slideshare.net/yeomii/deep-dive-into-flink-interval-join-208636345)
* [Here’s What Makes Apache Flink scale A glance at the Memory management and Network flow control](https://medium.com/walmartlabs/what-makes-apache-flink-scale-317f642fe6d5)
  * GC를 줄이기 위해 로딩시 Heap을 크게 잡아놓고 관리 (memory manager)
    * Operator에서 메모리가 필요할때 memory manager에 메모리(segment) 요청해서 꺼내쓰고 반환
    * 또한 network, disk I/O 속도 향상을 위해 off-heap으로 변환할수 있는 기능 제공 (stateful)
    * 커다란 segment를 Disk에 저장했다가 다시 읽기 가능. OOM 방지
  * 데이터 이동 최소화 [Operator chain 이용](https://ci.apache.org/projects/flink/flink-docs-stable/concepts/runtime.html#tasks-and-operator-chains)
  * 자체 serialize/deserialize 구현. object, 관련키(?), 해시 값을 인접하게 저장 가능. Data prefetch 가능
    * 값의 순서를 보장하기 때문에 정렬시 ser/dser 필요 없음. [Values로 되어있는 코드로 추정](https://github.com/apache/flink/tree/master/flink-core/src/main/java/org/apache/flink/types)
  * SubTask 중 한곳에 일이 몰려 backpressure로 인해 작업이 block되는것을 credit-based flow control로 방지
    * Subtask는 지금 buffer가 얼마남았는지 전단계의 SubTask에게 알려주고 전단계의 SubTask는 이를 고려하여 task 분배 [1](https://github.com/apache/flink/blob/master/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedPartitionRequestClientHandler.java) [2](https://github.com/apache/flink/blob/master/flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/CreditBasedSequenceNumberingViewReader.java)
* [OptimizedText.java](https://github.com/eastcirclek/terasort/blob/master/src/main/java/eastcircle/terasort/OptimizedText.java)
* [Improving throughput and latency with Flink's network stack - Nico Kruber](https://www.youtube.com/watch?v=AbqatHF3tZI) flink flow mechanism
* [Apache Flink Virtual Meetup Seoul July 23, 2020 - YouTube](https://www.youtube.com/watch?v=HWTb5kn4LvE)
  * [Flink on Kubernetes operator](https://www.slideshare.net/EuiHeo/flink-onkubernetesoperator-237435230)
* [Enriching your Data Stream Asynchronously with Apache Flink - YouTube](https://www.youtube.com/watch?v=UParyxe-2Wc)
* [Keynote | Flink Ahead 2.0: The Sequel - Konstantin Knauf - YouTube](https://www.youtube.com/watch?v=w2CAnHLGRuU)
* [Flink SQL in 2020: Time to show off! - Fabian Hueske & Timo Walther - YouTube](https://www.youtube.com/watch?v=UnCkwIp_614)
* [Unified APIs for Batch and Stream Processing on Flink - YouTube](https://www.youtube.com/watch?v=z9ye4jzp4DQ)
* [2021 Apache Flink Meetup - Hosted by Netflix - YouTube](https://www.youtube.com/watch?v=rtz3p_iijP8)
* [Flink setup for development (and some IntelliJ Idea cool tricks)](https://www.galiglobal.com/blog/2021/20210130-Flink-setup.html)
* [Flink Concept - Operator 간 데이터 교환 | leeyh0216's devlog](https://leeyh0216.github.io/posts/flink_output/)
* [Flink Concept - Checkpointing(1) | leeyh0216's devlog](https://leeyh0216.github.io/posts/flink_checkpoint_1/)
* [Flink Concept - pipeline.object_reuse | leeyh0216's devlog](https://leeyh0216.github.io/posts/flink_object_reuse/)
* [Flink Concept - Flink의 Kafka Consumer 동작 방식(1) | leeyh0216's devlog](https://leeyh0216.github.io/posts/flink_kafka_consumer_works_1/)
* [글로벌 기업이 더 주목하는 스트림 프로세싱 프레임워크 - 플링크(Flink) 이해하기 : 네이버 포스트](https://post.naver.com/viewer/postView.naver?volumeNo=31721490&memberNo=36733075&navigationType=push)
* [5 years of Flink at Mux | Mux blog](https://mux.com/blog/5-years-of-flink-at-mux/)
* [flink-ai-extended](https://github.com/alibaba/flink-ai-extended)
* [flink_feature_radar.svg at feature_radar · StephanEwen/flink-web](https://github.com/StephanEwen/flink-web/blob/feature_radar/img/flink_feature_radar.svg) flink에서 제거/추가될 기능들
* [Flink Job Listener: Run a task After Flink Job is Completed | CodersTea](https://www.coderstea.com/post/big-data/flink-job-listener-run-a-task-after-flink-job-is-completed/)
* HRFS [On-demand low-latency feature generation at Hyperconnect - YouTube](https://www.youtube.com/watch?v=jujAAaMQdF4)

# Flume
* [Scaling a flume agent to handle 120K events/sec](https://medium.com/data-collective/scaling-a-flume-agent-to-handle-120k-events-sec-11f70a428ca2)
  * Apache Flume용 새로운 channel selector인 "Round-Robin Channel Selector" 설명
  * 이 선택기를 사용하면 기본 배치 처리량의 약 10배까지 확장

# Geode
* [Geode - an open source, distributed, in-memory database for scale-out applications](http://geode.incubator.apache.org/)
* [Apache Geode Lab](https://github.com/Pivotal-Open-Source-Hub/StockInference-Spark/blob/master/Geode.md)

# Goblin
* [Goblin](https://github.com/apache/incubator-gobblin)

# HAWQ - advanced enterprise SQL-on-Hadoop query engine and analytic database
* [The Apache Software Foundation Announces Apache® HAWQ® as a Top-Level Project](https://blogs.apache.org/foundation/entry/the-apache-software-foundation-announces38)
* [Apache HAWQ 2.4.0.0 Release](https://cwiki.apache.org/confluence/display/HAWQ/Apache+HAWQ+2.4.0.0+Release)

# Hivemall
* [Hivemall](https://hivemall.incubator.apache.org/)
* [hivemall.incubator.apache.org/userguide/index.html](http://hivemall.incubator.apache.org/userguide/index.html)
* [Scalable machine learning library for Hive/Hadoop](https://github.com/myui/hivemall)
* [Apache Hivemall: Machine Learning Library for Apache Hive/Spark/Pig](http://www.slideshare.net/myui/dots20161029-myui)

# Iceberg
* [Iceberg - a table format for large, slow-moving tabular data](https://github.com/Netflix/iceberg)
* 넷플릭스, 대용량 자료 저장공간을 빠른 DB 테이블처럼 사용하는 기술
* [Iceberg: a fast table format for S3](https://www.slideshare.net/Hadoop_Summit/iceberg-a-fast-table-format-for-s3-103201179)
* [Iceberg: a fast table format for S3](https://www.youtube.com/watch?v=nWwQMlrjhy0)

# Ignite
* [Ignite](https://ignite.apache.org/features/igniterdd.html) - Spark Shared RDDs
* [Accelerate Apache Spark SQL Queries](https://ignite.apache.org/use-cases/spark/sql-queries.html)
* [Performance Tuning of an Apache Kafka/Spark Streaming System](https://mapr.com/blog/performance-tuning-apache-kafkaspark-streaming-system/)

# Impala
* [Impala](http://impala.io/)
* [Apache Impala (Incubating)](http://www.cloudera.com/products/apache-hadoop/impala.html)
* [Contributing to Impala](http://www.slideshare.net/cloudera/contributing-to-impala)
* [The Impala Cookbook](http://www.slideshare.net/cloudera/the-impala-cookbook-42530186)
* [What’s Next for Impala: More Reliability, Usability, and Performance at Even Greater Scale](http://blog.cloudera.com/blog/2015/07/whats-next-for-impala-more-reliability-usability-and-performance-at-even-greater-scale/)
* [How-to: Prepare Unstructured Data in Impala for Analysis](http://blog.cloudera.com/blog/2015/09/how-to-prepare-unstructured-data-in-impala-for-analysis/)
* [New SQL Benchmarks: Apache Impala (incubating) Uniquely Delivers Analytic Database Performance](http://blog.cloudera.com/blog/2016/02/new-sql-benchmarks-apache-impala-incubating-2-3-uniquely-delivers-analytic-database-performance/)
* [Announcing hs2client, A Fast New C++ / Python Thrift Client for Impala and Hive](http://blog.cloudera.com/blog/2016/06/announcing-hs2client-a-fast-new-c-python-thrift-client-for-impala-and-hive/)
* [Build a Prediction Engine Using Spark, Kudu, and Impala](https://dzone.com/articles/how-to-build-a-prediction-engine-using-spark-kudu)
* [Visualize your massive data with Impala and Redash](https://blog.chezo.uno/visualize-your-massive-data-with-impala-and-re-dash-afe31133c644)
* [Latest Impala Cookbook](http://blog.cloudera.com/blog/2017/02/latest-impala-cookbook/)
* [Ibis on Impala: Python at Scale for Data Science](http://blog.cloudera.com/blog/2015/07/ibis-on-impala-python-at-scale-for-data-science/)
* [SQL-on-Hadoop: Impala vs Drill](https://www.rittmanmead.com/blog/2017/04/sql-on-hadoop-impala-vs-drill/)
  * Apache Impala와 Apach Drill의 주요 구성 요소와 쿼리 처리 메커니즘에 대해 소개
* [Apache Impala Leads Traditional Analytic Database](http://blog.cloudera.com/blog/2017/04/apache-impala-leads-traditional-analytic-database-april-25th/)
  * Live, Spark, Presto와 TPC-DS 밴치마크 비교
* [How to read Impala query plan and profile? Part 1 and 2](https://www.cloudera.com/developers/featured-video.html)
* [Faster Performance for Selective Queries](http://blog.cloudera.com/blog/2017/12/faster-performance-for-selective-queries/)
* [Performance Optimizations in Apache Impala](https://www.slideshare.net/cloudera/performance-of-apache-impala)
  * 쿼리 최적화, 정렬 스캔(ordering scan & Top-N), 조인 패턴 및 이상적인 조인 유형 및 조인 순서 결정, 해시 조인, 집계을 위한 LLVM codegen, 런타임 블룸필터
* [Benchmarking Impala on Kudu vs Parquet](http://boristyukin.com/benchmarking-apache-kudu-vs-apache-impala/)
* [Hotspotting In Hadoop — Impala Case Study](https://medium.com/@adirmashiach/hotspotting-in-hadoop-impala-case-study-6a8a613f14a1)
* [Apache Impala: My Insights and Best Practices](https://medium.com/@adirmashiach/apache-impala-my-insights-and-best-practices-8e0507089935)
* [How to read Impala query plan and profile Part 1 by Juan Yu](https://www.cloudera.com/developers/featured-video.html)
* [5 Main Missing Features in Impala (Opinion)](https://medium.com/@adirmashiach/5-main-missing-features-in-impala-imo-1343c767081f)
* [Assessment of Apache Impala Performance using Cloudera Manager Metrics – Part 1 of 3](https://blog.cloudera.com/blog/2018/12/assessment-of-apache-impala-performance-using-cloudera-manager-metrics-part-1-of-3)
  * Cloudera Manger의 차트와 메트릭 기능을 사용하여 Impala 성능 이슈를 해결하는 방법
* [Impala At Scale - 임상배 이사 (Cloudera)](https://www.youtube.com/watch?v=8RlqL2kZ-NA)
* [practice - extract hour from unixtimestamp](https://gist.github.com/hyunjun/bc930e0bb463d8993ef11163895d6438#file-extract_hour_from_unixtimestamp-md)

# Jena
* [Jena](http://jena.apache.org)

# Kafka
* [Kafka](http://kafka.apache.org/)
* [kafka-tutorials.confluent.io](https://kafka-tutorials.confluent.io/)
* [Confluent Developer: Your Apache Kafka® Journey begins here](https://developer.confluent.io/)
* [Docker Quick Start](https://docs.confluent.io/current/installation/docker/docs/quickstart.html)
* [practice - Kafka on Python](https://hyunjun.github.io/kafka-on-python/)
  * [Kafka Python and Google Analytics](http://www.admintome.com/blog/kafka-python-and-google-analytics/)
  * [Getting started with Apache Kafka in Python](https://towardsdatascience.com/getting-started-with-apache-kafka-in-python-604b3250aa05)
* [Kafka For Beginners](https://medium.com/@rinu.gour123/kafka-for-beginners-74ec101bc82d)
* [주니어 개발자의 storm kafka 시작하기](http://blog.embian.com/m/post/108)
* [Kafka 시작하기 | FUREWEB](https://fureweb-com.github.io/blog/2020/02/23/kafka-tutorial.html)
* [Learn Kafka - Apache Kafka Tutorials and Resources | Confluent Developer](https://developer.confluent.io/learn-kafka/)
* [Apache Kafka and Confluent Platform examples and demos](https://github.com/confluentinc/examples)
* [**Apache Kafka Best Practices**](https://www.slideshare.net/HadoopSummit/apache-kafka-best-practices)
* [kafka-console-consumer.sh](http://documentation.kamanja.org/command-ref/kafka-console-consumer.html)
* [Kafka - kafka-console-consumer](https://gerardnico.com/wiki/dit/kafka/kafka-console-consumer)
* [Vertically scaling Kafka consumers](https://www.jesseyates.com/2019/12/04/vertically-scaling-kafka-consumers.html)
  * A look at the inner workings of the Kafka consumers, with some real world recommendations for deploying them when there's high latency in talking to the Kafka cluster and/or a large number of partitions. There are tips on important metrics to monitor, configurations, garbage collector settings, and changing the partition.class to improve unbalanced consumers.
* [KAFKA TUTORIAL: USING KAFKA FROM THE COMMAND LINE](http://cloudurable.com/blog/kafka-tutorial-kafka-from-command-line/index.html)
* [Kafka Tutorial - Quick Start Demo](https://www.youtube.com/watch?v=6AYNxdKQ_0o)
* [ClickHouse Kafka Engine Tutorial](https://www.altinity.com/blog/2020/5/21/clickhouse-kafka-engine-tutorial)
* [Introduction to Apache Kafka by James Ward](https://www.youtube.com/watch?v=UEg40Te8pnE)
* [Kafka frequent commands](https://gist.github.com/vkroz/05136cefdbb4fa61296993db17e1ae3f)
* [Kafka in a Nutshell](http://sookocheff.com/post/kafka/kafka-in-a-nutshell/)
* [빅데이터의 기본 아파치 카프카! 개요 및 설명 | What is apache kafka?](https://www.youtube.com/watch?v=waw0XXNX-uQ)
* [How To Install Apache Kafka on Ubuntu 14.04](https://www.digitalocean.com/community/tutorials/how-to-install-apache-kafka-on-ubuntu-14-04)
* [Apache Kafka. MacOS installation guide](https://medium.com/pharos-production/apache-kafka-macos-installation-guide-a5a3754f09c)
* [Install Kafka in RHEL 7](https://medium.com/@dindanovitasari/install-kafka-in-rhel-7-f15d10a07246)
* [Using Apache Kafka Docker](https://howtoprogram.xyz/2016/07/21/using-apache-kafka-docker/)
* [Kafka Docker - Run multiple Kafka brokers in Docker](https://wurstmeister.github.io/kafka-docker/)
* [kafka-stack-docker-compose](https://github.com/simplesteph/kafka-stack-docker-compose)
* [A Simple Apache Kafka Cluster With Docker, Kafdrop, and Python | by Leo Brack | Better Programming | Oct, 2020 | Medium](https://medium.com/better-programming/a-simple-apache-kafka-cluster-with-docker-kafdrop-and-python-cf45ab99e2b9)
* [HANDS-FREE KAFKA REPLICATION: A LESSON IN OPERATIONAL SIMPLICITY](http://blog.confluent.io/2015/04/07/hands-free-kafka-replication-a-lesson-in-operational-simplicity/)
* [Distributed Consensus Reloaded: Apache ZooKeeper and Replication in Apache Kafka](http://www.confluent.io/blog/distributed-consensus-reloaded-apache-zookeeper-and-replication-in-kafka)
* [Changing Replication Factor of a Topic in Apache Kafka](https://www.allprogrammingtutorials.com/tutorials/changing-replication-factor-of-topic-in-kafka.php)
* [Bottled Water: Real-time integration of PostgreSQL and Kafka](http://blog.confluent.io/2015/04/23/bottled-water-real-time-integration-of-postgresql-and-kafka/)
* [Apache Kafka, Samza, and the Unix Philosophy of Distributed Data](http://www.confluent.io/blog/apache-kafka-samza-and-the-unix-philosophy-of-distributed-data)
* [Apache Kafka: Case of Large Messages, Many Partitions, Few Consumers](https://olnrao.wordpress.com/2015/03/24/apache-kafka-case-of-large-messages-many-partitions-few-consumers/)
* [The Power of Kafka Partitions : How to Get the Most out of Your Kafka Cluster](https://www.instaclustr.com/the-power-of-kafka-partitions-how-to-get-the-most-out-of-your-kafka-cluster/)
* [From Kafka to ZeroMQ for real-time log aggregation](http://tomasz.janczuk.org/2015/09/from-kafka-to-zeromq-for-log-aggregation.html)
* [SQL on Kafka](https://www.pipelinedb.com/blog/sql-on-kafka)
* [Kafka at HubSpot: Critical Consumer Metrics](http://product.hubspot.com/blog/kafka-at-hubspot-part-1-critical-consumer-metrics)
* [Bottled Water: Real-time integration of PostgreSQL and Kafka](http://www.confluent.io/blog/bottled-water-real-time-integration-of-postgresql-and-kafka/)
* [빅데이터 윤활유 '아파치 카프카', 왜 주목받나](http://www.ciokorea.com/news/27214)
* [Why I am not a fan of Apache Kafka](https://gist.github.com/markrendle/26e423b6597685757732)
* [What’s New in Cloudera’s Distribution of Apache Kafka?](http://blog.cloudera.com/blog/2016/02/whats-new-in-clouderas-distribution-of-apache-kafka/)
* [Apache Kafka 성능 테스트](http://blog.embian.com/19)
* [Using Golang and JSON for Kafka Consumption With High Throughput](https://medium.com/the-hoard/using-golang-and-json-for-kafka-consumption-with-high-throughput-4cae28e08f90)
* [Golang에서 카프카 컨슈머 그룹과 재시도로 결과적 일관성 구현하기 | Popit](https://www.popit.kr/golang%EC%97%90%EC%84%9C-%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%BB%A8%EC%8A%88%EB%A8%B8-%EA%B7%B8%EB%A3%B9%EA%B3%BC-%EC%9E%AC%EC%8B%9C%EB%8F%84%EB%A1%9C-%EA%B2%B0%EA%B3%BC%EC%A0%81-%EC%9D%BC%EA%B4%80/)
* [대용량 스트리밍 데이터 실시간 분석](http://d2.naver.com/helloworld/7731491)
* [Monitoring Kafka performance metrics](https://www.datadoghq.com/blog/monitoring-kafka-performance-metrics/)
* [How to Monitor Kafka](https://blog.serverdensity.com/how-to-monitor-kafka/)
* [MONITORING APACHE KAFKA WITH GRAFANA / INFLUXDB VIA JMX](https://softwaremill.com/monitoring-apache-kafka-with-influxdb-grafana/)
* [카프카 커넥트 JMX + 로그스태시로 모니터링 하기](https://blog.voidmainvoid.net/375?category=698302)
* [Monitoring Kafka Consumer Offsets](https://blog.godatadriven.com/monitoring-kafka-consumer-lag)
  * Kafka consumer offset을 간단하게 모니터링하는 방법
  * Kafka consumer offset을 HTTP를 통해 내보내고 Prometheus를 사용하여 Grafana로 시각화
* [MONITORING KAFKA CONSUMER LAG IN SECONDS](https://hopsandthings.com/monitoring-kafka-consumer-lag-in-seconds/)
* [Apache Kafka Monitoring – Methods & Tools](https://data-flair.training/blogs/kafka-monitoring/)
* [Just Enough Kafka for the Elastic Stack, Part 1](https://www.elastic.co/blog/just-enough-kafka-for-the-elastic-stack-part1)
* [Elastic Stack에는 Kafka면 충분합니다 - 2부](https://www.elastic.co/kr/blog/just-enough-kafka-for-the-elastic-stack-part2)
* [Kafka New Producer API를 활용한 유실 없는 비동기 데이터 전송](http://readme.skplanet.com/?p=13042)
* [Kafka 0.9 Consumer 클라이언트 소개](http://www.popit.kr/kafka-0-9-consumer-%ED%81%B4%EB%9D%BC%EC%9D%B4%EC%96%B8%ED%8A%B8-%EC%86%8C%EA%B0%9C/)
* [Presto SQL을 이용하여 Kafka topic 데이터 조회하기](http://www.popit.kr/presto-sql%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC-kafka-topic-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A1%B0%ED%9A%8C%ED%95%98%EA%B8%B0/)
* [New in Cloudera Enterprise 5.8: Flafka Improvements for Real-Time Data Ingest](http://blog.cloudera.com/blog/2016/08/new-in-cloudera-enterprise-5-8-flafka-improvements-for-real-time-data-ingest/)
* [Kafka Python client 성능 테스트](http://www.popit.kr/kafka-python-client-%EC%84%B1%EB%8A%A5-%ED%85%8C%EC%8A%A4%ED%8A%B8/)
* [Understanding of Apache Kafka – Part.1](http://bitnine.net/blog-computing/understanding-of-apache-kafka-part-1/)
* [From Big Data to Fast Data in Four Weeks or How Reactive Programming is Changing the World – Part 1](https://www.paypal-engineering.com/2016/11/08/from-big-data-to-fast-data-in-four-weeks-or-how-reactive-programming-is-changing-the-world-part-1/)
* [Apache Kafka, Data Pipelines, and Functional Reactive Programming with Node.js](https://blog.heroku.com/kafka-data-pipelines-frp-node)
* [Building/Runn­i­ng Netflix's Data Pipeline using Apache Kafka](https://www.meetflix.org/tldr/57fc672f25fff9338f1dfc9c/view)
* [코드 한줄 없이 서비스 Dashboard 만들기(1)](http://www.popit.kr/%EC%BD%94%EB%93%9C-%ED%95%9C%EC%A4%84-%EC%97%86%EC%9D%B4-%EC%84%9C%EB%B9%84%EC%8A%A4-dashboard-%EB%A7%8C%EB%93%A4%EA%B8%B0-1/)
* [코드 한줄 없이 서비스 Dashboard 만들기(2)](http://www.popit.kr/%EC%BD%94%EB%93%9C-%ED%95%9C%EC%A4%84-%EC%97%86%EC%9D%B4-%EC%84%9C%EB%B9%84%EC%8A%A4-dashboard-%EB%A7%8C%EB%93%A4%EA%B8%B02/)
* Kafka 운영자가 말하는
  * [처음 접하는 Kafka](http://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-%EC%B2%98%EC%9D%8C-%EC%A0%91%ED%95%98%EB%8A%94-kafka/)
  * [Kafka Consumer Group](http://www.popit.kr/kafka-consumer-group/)
  * [Producer ACKS](http://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-producer-acks/)
  * [카프카 서버 실전 로그 분석](http://www.popit.kr/%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%84%9C%EB%B2%84-%EC%8B%A4%EC%A0%84-%EB%A1%9C%EA%B7%B8-%EB%B6%84%EC%84%9D/)
  * [TIP](http://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-tip/)
  * [Topic Replication](http://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-topic-replication/)
  * [Replication Factor 변경](https://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-replication-factor-%EB%B3%80%EA%B2%BD/)
  * [카프카 매니저 소개](https://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-%EC%B9%B4%ED%94%84%EC%B9%B4-%EB%A7%A4%EB%8B%88%EC%A0%80-%EC%86%8C%EA%B0%9C/)
* [Kafka Summit Americas 2021 Recap | Confluent](https://www.confluent.io/blog/kafka-summit-americas-2021-recap/)
* [Kafka Summit New York](https://kafka-summit.org/kafka-summit-ny/schedule/)
* [Kafka Summit New York 2019 Session Videos](https://www.confluent.io/blog/kafka-summit-new-york-2019-session-videos)
* [Kafka Summit San Francisco](https://www.confluent.io/resources/kafka-summit-san-francisco-2019/)
  * [Kafka Needs no Keeper](https://www.confluent.io/kafka-summit-san-francisco-2019/kafka-needs-no-keeper)
    * Kafka 2.4 들어가면서 zookeeper 가 사라지고 kafka controller broker 가 그 역할을 대신하는데, 어떻게 없앴고 어떤 변화가 있는지에 대한 세션
    * Elasticsearch 운영 경험이 있으신 분들은 kafka controller 가 es master-eligible node 와 비슷한 느낌
  * [Please Upgrade Apache Kafka. Now](https://www.confluent.io/kafka-summit-san-francisco-2019/please-upgrade-apache-kafka-now)
    * Kafka: The Definitive Guide 의 저자이기도 한 Gwen이 오래된 Kafka 버젼들에 존재하는 각종 버그들과 취약점들을 여러가지 소개하면서 업그레이드 해야 할 이유를 설명하는 세션
* [Martin Kleppmann | Kafka Summit London 2019 Keynote | Is Kafka a Database?](https://www.youtube.com/watch?v=BuE6JvQE_CY)
  * [Online Event Processing Achieving consistency where distributed transactions have failed](https://queue.acm.org/detail.cfm?id=3321612)
* [The First Annual State of Apache Kafka Client Use Survey](https://www.confluent.io/blog/first-annual-state-apache-kafka-client-use-survey/) Kafka와 함께 어떤 언어를 많이 사용하는지와 이유
* [Benchmarking Kafka Performance Part 1: Write Throughpu](https://hackernoon.com/benchmarking-kafka-performance-part-1-write-throughput-7c7a76ab7db1)
* [Securing the Confluent Schema Registry for Apache Kafaka](https://www.confluent.io/blog/securing-confluent-schema-registry-apache-kafka/)
  * Confluent Schema Registry를 보호하고 ZooKeeper 및 Kafka 클러스터 보안 연결하도록 구성하는 방법 소개
* [Introduction to Apache Kafka Security](https://medium.com/@stephane.maarek/introduction-to-apache-kafka-security-c8951d410adf)
* [Apache Kafka Security | Need and Components of Kafka](https://medium.com/@rinu.gour123/apache-kafka-security-need-and-components-of-kafka-52b417d3ca77)
  * Zookeeper의 조합으로 권한제어, 인증제어, 암호화하는 방법
* [Kafka Needs No Keeper - Removing ZooKeeper Dependency](https://www.confluent.io/blog/removing-zookeeper-dependency-in-kafka/)
  * [Apache Kafka, ZooKeeper 의존성을 제거 | GeekNews](https://news.hada.io/topic?id=2100)
* [Kafka Without ZooKeeper: A Sneak Peek At the Simplest Kafka Yet](https://www.confluent.io/blog/kafka-without-zookeeper-a-sneak-peek/)
  * [Kafka Without ZooKeeper 첫 배포 | GeekNews](https://news.hada.io/topic?id=3990)
* [Kafka Needs no Keeper - Confluent](https://www.confluent.io/kafka-summit-san-francisco-2019/kafka-needs-no-keeper/)
  * [kafka/config/kraft at trunk · apache/kafka](https://github.com/apache/kafka/tree/trunk/config/kraft)
* [Kafka 보안 (1) - JAAS 및 SASL](https://springboot.cloud/31)
* [Kafka 보안 (2) - SASL/PLAIN](https://springboot.cloud/32)
* [**Apache Kafka지도 시간**](http://www.w3ii.com/ko/apache_kafka/default.html)
* [Exactly-once Support in Apache Kafka](https://medium.com/@jaykreps/exactly-once-support-in-apache-kafka-55e1fdd0a35f)
* [Exactly-once Semantics are Possible: Here’s How Kafka Does it](https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/)
* [kafka exactly-once delivery를 지원하기 위한 transaction](https://blog.voidmainvoid.net/354)
* [Upgrading Apache Kafka Clients Just Got Easier](https://www.confluent.io/blog/upgrading-apache-kafka-clients-just-got-easier/)
  * 최신 버전에 Kafka 클라이언트의 순방향/역방향 호환성 추가
  * 이 기능을 사용하는 방법 및 브로커와 다른 버전의 클라이언트를 사용할 경우에 대해 설명
* [How to Build and Deploy Scalable Machine Learning in Production with Apache Kafka](https://www.confluent.io/blog/build-deploy-scalable-machine-learning-production-apache-kafka/)
  * 미션 크리티컬한 실시간 애플리케이션에서 중앙집중적이고 확장가능한 아키텍처를 어떻게 만들지에 대한 유스케이스에 대해 논의
* [Benchmarking Message Queue Latency](https://bravenewgeek.com/benchmarking-message-queue-latency/)
* [How Apache Kafka Inspired Our Platform Events Architecture](https://engineering.salesforce.com/how-apache-kafka-inspired-our-platform-events-architecture-2f351fe4cf63)
* [How to know if Apache Kafka is right for you](https://medium.freecodecamp.org/how-to-know-if-apache-kafka-is-right-for-you-1b2e468d52b9)
* [URP? Excuse You! The Three Kafka Metrics You Need to Know](https://www.slideshare.net/ToddPalino/urp-excuse-you-the-three-kafka-metrics-you-need-to-know) under replicated partition, request handler, requst time에 대해 모니터링할 수 있는 Kafka 메트릭 설명
* [Top 5 Things Every Apache Kafka Developer Should Know](https://www.confluent.io/blog/5-things-every-kafka-developer-should-know/)
* [일상 협업 이야기: 참조 아키텍처 써먹기 편](https://www.popit.kr/v2/%EC%9D%BC%EC%83%81-%ED%98%91%EC%97%85-%EC%9D%B4%EC%95%BC%EA%B8%B0-%EC%B0%B8%EC%A1%B0-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98-%EC%8D%A8%EB%A8%B9%EA%B8%B0-%ED%8E%B8)
* [Scalability of Kafka Messaging using Consumer Groups](http://blog.cloudera.com/blog/2018/05/scalability-of-kafka-messaging-using-consumer-groups/)
* [Announcing AMQ Streams: Apache Kafka on OpenShift](https://developers.redhat.com/blog/2018/05/07/announcing-amq-streams-apache-kafka-on-openshift/)
* [Robust Message Serialization in Apache Kafka Using Apache Avro, Part 1](http://blog.cloudera.com/blog/2018/07/robust-message-serialization-in-apache-kafka-using-apache-avro-part-1/)
  * 아파치 카프카(Apache Kafka)에서는 producer라고 하는 Java 애플리케이션으로 구조화된 메시지를 써서 카프카 클러스터(브로커로 구성됨)로 전송. 이들 메시지를 읽는 작업도 마찬가지로 같은 클러스터에서 consumer라는 Java 애플리케이션이 담당. 조직에 따라서 각기 다른 그룹이나 부서에서 producer와 consumer를 쓰고 관리하는 책임을 전담
    * 이런 경우 한 가지 중대한 이슈가 발생. 즉 producer와 consumer 사이에서 서로 합의된 메시지 형식을 조율 필요
    * 예시는 아파치 아브로(Apache Avro)를 사용하여 아파치 카프카를 대상으로 생성된 레코드를 직렬화하면서 스키마를 개발, producer와 consumer 애플리케이션을 비동기식으로 업데이트하는 방법
  * 직렬화와 역직렬화
    * 한 개의 카프카 레코드(기존에는 ‘메시지’라고 불림)는 한개의 키, 한개의 값, 헤더로 구성. 카프카는 레코드의 키와 값 면에서 데이터의 구조 인식 불가능. 대신 바이트 어레이 형태로 취급
    * 하지만 카프카로부터 레코드를 읽는 시스템의 입장에서는 이러한 레코드에 포함된 데이터가 중요. 따라서 데이터를 읽을 수
있는 형식으로 도출할 필요
    * 사용해야 하는 데이터 형식의 특성
      * 컴팩트
      * 빠른 인코딩과 디코딩 가능
      * 변화(evolution) 허용
      * 업스트림 시스템(카프카 클러스터에 데이터를 쓰는 시스템)과 다운스트림 시스템(같은 카프카 클러스터에서 데이터를 읽어오는 시스템)이 각기 다른 시점에 새 스키마로 업그레이드 허용
    * 예를 들어 JSON의 경우 설명이 따로 필요 없지만 컴팩트 데이터 형식이 아니고 구문 분석 저속
    * 아브로는 비교적 컴팩트한 출력 데이터를 생성하는 고속 직렬화 프레임워크. 하지만 아브로 레코드를 읽으려면 데이터를 직렬화하는 데 사용한 스키마 필요
    * 한 가지 옵션은 스키마를 레코드 자체와 함께 저장하고 전송. 이 방법은 스키마를 한 번만 저장했다가 다수의 레코드에 사용하는 경우 가능. 카프카 레코드마다 모두 스키마를 하나씩 저장하려면 스토리지 공간과 네트워크 활용도 면에서 중대한 오버헤드 추가
    * 또 한 가지 옵션은 미리 합의한 식별자 스키마 매핑 세트를 정하여 스키마를 레코드 내에 존재하는 각각의 식별자로 참조
* [Robust Message Serialization in Apache Kafka Using Apache Avro, Part 2](http://blog.cloudera.com/blog/2018/07/robust-message-serialization-in-apache-kafka-using-apache-avro-part-2/)
  * 스키마 저장소 구현; 저장소로서 Apache Kafka와 함께 작동하는 스키마 공급자 구현
  * 인 메모리 SchemaStore
    * 먼저 스키마를 위한 인 메모리 저장소 구현 가능. 이는 이러한 저장소 및 Kafa지원 저장소 캐시 요건을 이해하는 데 유용. SchemaStore는 VersionedSchema 항목 검색이 신속해야 하기 때문에, 각 검색 방법을 지원하기 위해 별도의 맵을 작성. ConcurrentHashMap을 사용하면 잠김 없이 복수의 스레드로부터 이들 맵에 접근 가능
  * Kafka Topic에서/으로 쓰기 및 읽기
    * Kafka 기반 SchemaProvider의 나머지 반은 Kafka와 모든 커뮤니케이션을 수행할 수 있는 클래스. 이것은 스키마 컨셉에 묶일 필요가 없어 제네릭 코드로도 가능. 시작 시 모든 스키마를 읽고 새로운 스키마를 위해 계속 폴링하도록 하기 위해 다음과 같이 소비자를 설정
    * enable.auto.commit =false, 시작시 모든 스키마를 다시 읽기 때문
    * 우연히 group.id가 같은 다른 소비자와 메시지를 공유하지 않도록 모든 파티션을 해당 소비자에 수동으로 할당
    * 읽기 전 가장 오래된 메시지 검색
    * 최신 기록을 읽어 들일 때까지 폴링한 후 스키마 공급자 사용을 허용
    * 새로운 스키마를 받기 위해 백그라운드 스레드에서 폴링 지속
  * 한 가지 중요한 문제는 스키마 식별자 생성
    * Kafka에는 RDBMS와 같은 시퀀스 개체가 없기 때문에, 추가하는 스키마마다 고유한 정수 필요. 이에 대한 한 가지 간단한 해결 방법은 다음으로 사용 가능한 양(+)의 정수를 검색. 이 경우, 두 명의 관리자가 동일한 식별자로 거의 동시에 스키마를 추가하지 못하도록 막기는 불가능. 이를 막기 위해서 다음과 같이 진행
    * 단일 파티션이 있는 Kafka Topic을 시퀀스로 사용. 단일 메시지를 생성하고 그 오프셋을 사용
    * ZooKeeper 임시 노드를 사용하여 “잠급니다.”
    * 스키마를 추가하는 서비스 도입. 이 애플리케이션은 메모리를 잠그는 게 가능
    * 소수만 접근할 수 있는 주체에 스키마를 저장한 토픽으로 쓰기를 허용하며 책임을 위임
* [Understanding the ‘enable.auto.commit’ Kafka Consumer property](https://medium.com/@danieljameskay/understanding-the-enable-auto-commit-kafka-consumer-property-12fa0ade7b65)
* [Robust Message Serialization in Apache Kafka Using Apache Avro, Part 3](https://blog.cloudera.com/blog/2018/08/robust-message-serialization-in-apache-kafka-using-apache-avro-part-3/)
* [Interview with Jay Kreps about Apache Kafka](https://notamonadtutorial.com/interview-with-jay-kreps-about-apache-kafka-46fbfdb870ca)
* [RDBMS to Kafka: Stories from the Message Bus Stop](https://www.youtube.com/watch?v=mFxb6WkBRqo)
* [카프카, 산전수전 노하우](https://www.slideshare.net/ifkakao/ss-113145591)
* [Kafka timestamp offset](https://www.slideshare.net/charsyam2/kafka-timestamp-offset)
* [Resetting first dirty offset to log start offset since the checkpointed offset is invalid](https://donald-dh.github.io/donald-dh.github.io/ts-kafka-resetting-first-dirty-offset/)
* [Kafka 0.10 Compression Benchmark](http://blog.yaorenjie.com/2017/01/03/Kafka-0-10-Compression-Benchmark/)
* [How to use Apache Kafka to transform a batch pipeline into a real-time one](https://medium.com/@stephane.maarek/how-to-use-apache-kafka-to-transform-a-batch-pipeline-into-a-real-time-one-831b48a6ad85)
* [Kafka Korea meetup](https://github.com/kafkakru/meetup)
  * [About 1st Conference](https://github.com/kafkakru/meetup/tree/master/conference/1st-conference)
  * [**KafkaKRU(Kafka 한국사용자 모임) 2회 미니밋업 후기**](https://zzsza.github.io/etc/2019/03/26/kafkakru-2nd-review/)
  * [Kafka kru CONFERENCE SEOUL 2019 후기 & 정리글](https://dabo-dev.tistory.com/17)
  * [mini-meetup2](https://github.com/kafkakru/meetup/tree/master/mini-meetup2)
  * [About 3rd Mini-Meetup](https://github.com/kafkakru/meetup/tree/master/mini-meetup3)
  * [Kafka Conference Seoul 2019](https://www.youtube.com/channel/UCbEFe27NO28kxV2BSWsQe5g)
  * [카프카 기반의 대규모 모니터링 플랫폼 개발이야기](https://www.slideshare.net/ifkakao/2019-kafkakru-issac)
* [Moving From Legacy To Event-Driven With Kafka](https://www.youtube.com/watch?v=H_ang8BatXQ)
* [CDC & CDC Sink Platform 개발 1편 - CDC Platform 개발 | Hyperconnect Tech Blog](https://hyperconnect.github.io/2021/01/11/cdc-platform.html) Event Bus, Event Driven
* [CDC & CDC Sink Platform 개발 2편 - CDC Sink Platform 개발 및 CQRS 패턴의 적용 | Hyperconnect Tech Blog](https://hyperconnect.github.io/2021/03/22/cdc-sink-platform.html)
* [CDC & CDC Sink Platform 개발 3편 - CDC Event Application Consuming 및 Event Stream Join의 구현 | Hyperconnect Tech Blog](https://hyperconnect.github.io/2021/06/21/cdc-event-application-consuming.html)
* [카프카 컨슈머 애플리케이션 배포 전략](https://medium.com/11st-pe-techblog/%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%BB%A8%EC%8A%88%EB%A8%B8-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EB%B0%B0%ED%8F%AC-%EC%A0%84%EB%9E%B5-4cb2c7550a72)
* [**cloudurable.com/categories/kafka**](http://cloudurable.com/categories/kafka/index.html)
  * [**Kafka Tutorial 13: Creating Advanced Kafka Producers in Java**](http://cloudurable.com/blog/kafka-tutorial-kafka-producer-advanced-java-examples/index.html)
    * 압축방식은 lz4가 좋으며, decompress할때 사이즈 넣어야 snappy보다 느린 현상이 발생하지 않음
* [Introduction to Schemas in Apache Kafka with the Confluent Schema Registry](https://medium.com/@stephane.maarek/introduction-to-schemas-in-apache-kafka-with-the-confluent-schema-registry-3bf55e401321)
  * kafka는 json에 대한 serde를 제공하지 않음(구현은 가능)
  * json보다 avro를 쓸 이유
    * confluent schema registy (schema 정보를 가지고 있는 저장소) 기준
      * 1. 데이터 축소 : 필드명을 보내지 않아도 됨 >> 데이터 : 매직바이트 + schemaID + value
      * 2. producing 되는 데이터의 스키마가 변경되면 schema registry에 등록이나 수정만 하면되니 consumer는 수정하지 않아도 될 가능성이 높음
    * json 처럼 schema가 free 한 경우 잦은 schema의 변경으로 producing 되는경우 consumer는 수정이 불가피 하며 스키마의 대한 정보를 놓치기 쉽고 이력도 알수 없음
* [(Kafka) 객체를 JSON 타입으로 넘겨보자 :: 당근케잌](https://yeon-kr.tistory.com/181)
* [Securing the Confluent Schema Registry for Apache Kafka](https://www.confluent.io/blog/securing-confluent-schema-registry-apache-kafka/)
* [Kafka 스키마 관리, Schema Registry](https://dol9.tistory.com/274)
    * 하지만 avro 를 사용하면 변경된 스키마를 가진 데이터의 무분별한 producing을 막을수 있음
* [Apache Kafka Supports 200K Partitions Per Cluster](https://www.confluent.io/blog/apache-kafka-supports-200k-partitions-per-cluster)
  * 카프카 클러스터에서 파티션 수. 클러스터 내 브로커 한대 기준
  * 1.1.0 이전 2,000 ~ 4,000개 정도가 적절, 1.1.0 릴리즈 이후부터는 약 200,000개 까지 가능
  * 이렇게 큰 변화가 있게 된 원인은, 주키퍼에 변경되는 업데이트를 async 처리하고, 브로커에 새로운 리더 정보 업데이트를 배치로 일괄 처리함으로써, 1.1.0 릴리즈 이전 버전보다 속도가 향상
* [Kafka 생태계 들여다보기](https://speakerdeck.com/dongjin/kafka-ecosystem-explained)
* [Big Data, Fast Data @ PayPal](https://www.slideshare.net/r39132/big-data-fast-data-paypal)
  * Paypal 데이터 플랫폼 이야기. CDC(Change Data Capture)와 Kafka와 Avro를 같이 사용해야 하는 이유 등 아키텍처에 대해 설명
* [An Overview of Kafka Distributed Message System](https://www.alibabacloud.com/blog/an-overview-of-kafka-distributed-message-system_594218)
  * Apache Kafka 개념 설명
* [Kafka의 디스크가 모자랄 때](https://andromedarabbit.net/kafka%EC%9D%98-%EB%94%94%EC%8A%A4%ED%81%AC%EA%B0%80-%EB%AA%A8%EC%9E%90%EB%9E%84-%EB%95%8C/)
* [New Features of Kafka 2.1](https://medium.com/@stephane.maarek/new-features-of-kafka-2-1-33fb5396b546)
* [카프카를 활용한 워크 큐](https://www.popit.kr/%EC%B9%B4%ED%94%84%EC%B9%B4%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%9B%8C%ED%81%AC-%ED%81%90/)
  * 기술보다는 뭘 어떤 방향으로 만들지에 대한 이야기
* How to Lose Messages on a Kafka Cluster
  * [Part 1](https://jack-vanlightly.com/blog/2018/9/14/how-to-lose-messages-on-a-kafka-cluster-part1)
  * [Part 2](https://jack-vanlightly.com/blog/2018/9/18/how-to-lose-messages-on-a-kafka-cluster-part-2)
* [Kafka 클러스터 메세지 발행 및 문제 해결 :: 당근케잌](https://yeon-kr.tistory.com/186)
* [Kafka Using Java. Part 1](https://medium.com/pharos-production/kafka-using-java-e10bfeec8638)
* [Kafka Using Java. Part 2](https://medium.com/pharos-production/kafka-using-java-part-2-83fd604ed627)
* [**blog.voidmainvoid.net/category/.../Kafka**](https://blog.voidmainvoid.net/category/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0/Kafka)
  * [blog.voidmainvoid.net/tag/kafka](https://blog.voidmainvoid.net/tag/kafka)
  * [Kafka broker와 java client의 버젼 하위호환성 정리](https://blog.voidmainvoid.net/193)
* [Finding Kafka’s throughput limit in Dropbox infrastructure](https://blogs.dropbox.com/tech/2019/01/finding-kafkas-throughput-limit-in-dropbox-infrastructure/)
* [Kafka, Producer 부터 Consumer 까지](https://docs.google.com/presentation/d/16ZoY4QLpbAqHcCISaURCKXGNGs9sG809Pi4MHLsdKNA/)
* [kafka-multiprocessing-producer.py](https://gist.github.com/outtoin/12d1334b1345403c57372fcc6653c11b) 정상 동작하는 지 점검 필요
* [kafka-tutorials.com](https://www.kafka-tutorials.com)
* [Kafka Using Java. Part 1](https://medium.com/pharos-production/kafka-using-java-e10bfeec8638)
* [Kafka Using Java. Part 2](https://medium.com/pharos-production/kafka-using-java-part-2-83fd604ed627)
* [Kafka, Java, and Bitcoin](https://medium.com/pharos-production/kafka-java-and-bitcoin-cf0009767645)
* [What's New in Kafka 2.2?](https://www.youtube.com/watch?v=kaWbp1Cnfo4)
* [Understanding Kafka with Factorio](https://hackernoon.com/understanding-kafka-with-factorio-74e8fc9bf181)
* [Kerberos 인증 #1](https://devidea.tistory.com/79)
* [Kerberos 인증 #2](https://devidea.tistory.com/80)
* [**카프카 설치 시 가장 중요한 설정 4가지**](https://www.popit.kr/%EC%B9%B4%ED%94%84%EC%B9%B4-%EC%84%A4%EC%B9%98-%EC%8B%9C-%EA%B0%80%EC%9E%A5-%EC%A4%91%EC%9A%94%ED%95%9C-%EC%84%A4%EC%A0%95-4%EA%B0%80%EC%A7%80/)
* [**kafka 운영 - 기본적인 환경 설정 경험담**](https://springboot.cloud/34)
* [**KAFKA와 그 친구들**](https://speakerdeck.com/dongjin/kafka-and-friends-ko) monitoring, 운영, test tool 소개
* [How to use reassign partition tool in Apache Kafka](https://www.youtube.com/watch?v=sWsWurfBI9c)
* [How to move Kafka Partition log directory within a Broker Node](https://www.youtube.com/watch?v=UrX2RWM2vQQ)
* [How to use reassign partition tool in Apache Kafka](https://www.youtube.com/watch?v=sWsWurfBI9c)
* [KAFKA ARCHITECTURE: LOG COMPACTION](http://cloudurable.com/blog/kafka-architecture-log-compaction/index.html)
* [Log Compacted Topics in Apache Kafka](https://towardsdatascience.com/log-compacted-topics-in-apache-kafka-b1aa1e4665a7)
  * Consumer Offset 정보가 `__consumer_offsets`라는 토픽에 저장, 그 토픽의 cleanup.policy가 Compact 로 설정
* [Log Management in Apache Kafka - Speaker Deck](https://speakerdeck.com/dongjin/log-management-in-apache-kafka)
* [kafka 운영 - kafka의 Exception들 - (1)](https://springboot.cloud/35)
* [Kafka 로그 종류 및 로그 샘플에 대한 설명](https://godway1225.wordpress.com/2019/08/29/kafka-로그-종류-및-로그-샘플에-대한-설명)
* [kafka 개발 - AdminClient 로 관리 기능 개발하기 - Broker 정보 보기](https://springboot.cloud/36)
* [카프카 서버 디스크 최적화](https://www.popit.kr/카프카-서버-디스크-최적화/)
* [BUILDING A RELATIONAL DATABASE USING KAFKA](https://yokota.blog/2019/09/23/building-a-relational-database-using-kafka/) KarelDB, KCache, Avro, Calcite, Omid, Avatica
* [**devidea.tistory.com/category/Big Data/Kafka**](https://devidea.tistory.com/category/Big%20Data/Kafka)
  * [컨트롤러 분석](https://devidea.tistory.com/71)
* [How LinkedIn customizes Apache Kafka for 7 trillion messages per day](https://engineering.linkedin.com/blog/2019/apache-kafka-trillion-messages)
* [LINE에서 Kafka를 사용하는 방법 – 1편](https://engineering.linecorp.com/ko/blog/how-to-use-kafka-in-line-1/)
* [LINE에서 Kafka를 사용하는 방법 – 2편](https://engineering.linecorp.com/ko/blog/how-to-use-kafka-in-line-2/)
* [카프카를 쿠버네티스 위에 올리는게 좋은 선택일까?](https://blog.voidmainvoid.net/280)
* [Running Apache Kafka on Kubernetes](https://www.youtube.com/watch?v=Zq6UTdff45k)
* [아파치 카프카🚀를 알아야하는 이유! 카프카의 미래? 앞으로 어떻게될까?](https://www.youtube.com/watch?v=lEOV4upTJ68)
* [Serverless Kafka on Kubernetes | DevNation Live](https://www.youtube.com/watch?v=bL9e1xt2TuA)
* [Apache Kafka Producer Improvements with the Sticky Partitioner](https://www.confluent.io/blog/apache-kafka-producer-improvements-sticky-partitioner/)
* [KafkaProducer Client Internals](https://d2.naver.com/helloworld/6560422)
* [Incremental Cooperative Rebalancing in Apache Kafka: Why Stop the World When You Can Change It?](https://www.confluent.io/blog/incremental-cooperative-rebalancing-in-kafka/)
* [강의 - 아파치 카프카](https://www.youtube.com/playlist?list=PL3Re5Ri5rZmkY46j6WcJXQYRlDRZSUQ1j)
* [kubernetes, python, kafka 메모](https://sangwook.github.io/2017/08/27/kubernetes-python-kafka.html)
* [Using graph algorithms to optimize Kafka operations, Part 1](https://medium.com/pinterest-engineering/using-graph-algorithms-to-optimize-kafka-operations-part-1-abbabd606a25)
* [Using graph algorithms to optimize Kafka operations, Part 2](https://medium.com/@Pinterest_Engineering/using-graph-algorithms-to-optimize-kafka-operations-part-2-c970d9c08c7d)
* [Apache Kafka as a Service with Confluent Cloud Now Available on Azure Marketplace](https://www.confluent.io/blog/confluent-cloud-managed-kafka-service-azure-marketplace/)
* [**카프카 컨슈머 멀티쓰레드 애플리케이션 예제코드(for scala)**](https://blog.voidmainvoid.net/313)
* [링크드인은 왜 카프카를 만들었나](http://www.hanbit.co.kr/channel/category/category_view.html?cms_code=CMS9400468504)
* [링크드인이 카프카를 직접 개발한 이유 - 테크잇](https://techit.kr/view/?no=20200815134042)
* [Disaster Recovery Plans for Apache Kafka](https://www.slideshare.net/ConfluentInc/disaster-recovery-plans-for-apache-kafka)
* [Resiliency and Disaster Recovery with Kafka | by eBay TechBlog | eBayTech | Medium](https://medium.com/ebaytech/resiliency-and-disaster-recovery-with-kafka-dc8901c881c)
* [카프카 클러스터 클러스터ip DNS 연동방법. use_all_dns_ips 사용(in AWS, route53)](https://blog.voidmainvoid.net/327)
* [Is Apache Kafka a Database? - The 2020 Update](https://dzone.com/articles/is-apache-kafka-a-database-the-2020-update)
* [Kafka-client client.dns.lookup 옵션 정리](https://blog.voidmainvoid.net/331)
* [기본 개념잡기](https://victorydntmd.tistory.com/344)
* [Ordering of events in Kafka](https://medium.com/@siddhbhatt/ordering-of-events-in-kafka-e5692663e708)
* [Why Kafka Is so Fast. Discover the deliberate design… | by Emil Koutanov | The Startup | Medium](https://medium.com/swlh/why-kafka-is-so-fast-bde0d987cd03)
* [Is Apache Kafka a Database?. Can and should Apache Kafka replace a… | by Kai Waehner | Medium](https://medium.com/@megachucky/is-apache-kafka-a-database-ddc310898f5c)
* [kafka 아는 척하기 (개발자용) :: 자바캔(Java Can Do IT)](https://javacan.tistory.com/entry/kafka-intro-1-for-developers)
* [Kafka is not a Database – Materialize](https://materialize.com/kafka-is-not-a-database/)
* [Sizing Calculator for Apache Kafka and Confluent Platform](https://eventsizer.io/)
* [Thread-Per-Core Buffer Management for a modern Kafka-API storage system - Vectorized](https://vectorized.io/blog/tpc-buffers/)
* [Introducing Confluent’s Parallel Consumer Message Processing Client](https://www.confluent.io/blog/introducing-confluent-parallel-message-processing-client/)
* [Intro to Apache Kafka: How Kafka Works](https://www.confluent.io/blog/apache-kafka-intro-how-kafka-works/)
* [Kafka Operations(Production Deployment) – Sori-Nori](https://sori-nori.gitlab.io/docs/Kafka-Operations/)
* [Disaster Recovery for Multi-Region Kafka at Uber | Uber Engineering Blog](https://eng.uber.com/kafka/)
  * [summary](https://gist.github.com/hyunjun/c176ac5d9f9dcc478ac6c28f56ca2b6f#file-uber_kafka_summary)
* [How Zendesk Secures Kafka with Self-Hosted mTLS Authentication System](https://www.confluent.io/blog/how-zendesk-secures-kafka-with-mtls-authentication-system/)
* [Property Based Testing Confluent Cloud Storage for Fun and Safety](https://www.confluent.io/blog/property-based-testing-confluent-tiered-storage/)
* [**Kafka on Kubernetes, minimal configuration**](https://gist.github.com/dongjinleekr/fcadc20063553935cfb6536185421ca2)
* [Beyond the Brokers: A Tour of the Kafka Ecosystem](https://www.slideshare.net/ConfluentInc/beyond-the-brokers-a-tour-of-the-kafka-ecosystem-138678797)
* [스케일아웃없이 순간 급증하는 주문 처리하기 (Microservice with Kafka)](https://tv.naver.com/v/11212897)
* [Kafka for Engineers. Here are things about Kafka that you… | by Dave Taubler | Level Up Coding](https://levelup.gitconnected.com/kafka-for-engineers-975feaea6067)
* [Kafka 운영 컨슈머 그룹 정보는 언제 사라질까? :: 언제나 김김](https://always-kimkim.tistory.com/entry/when-will-the-kafka-consumer-group-be-removed)
* [a-great-day-out-with/a-great-day-out-with.github.io](https://github.com/a-great-day-out-with/a-great-day-out-with.github.io)
  * [A Great Day Out With... Apache Kafka](https://a-great-day-out-with.github.io/kafka.html)
* [KafkaConsumer Client Internals](https://d2.naver.com/helloworld/0974525)
* [Apache Kafka for Industrial IoT and Manufacturing 4.0 - Kai Waehner](https://www.kai-waehner.de/blog/2021/05/19/apache-kafka-industrial-iot-manufacturing-4-0-automotive-energy-logistics/)
* [Cannot get state store TOPIC because the stream thread is STARTING, not RUNNING 에러 해결](https://voidmainvoid.tistory.com/443) ktable
* [A gentle introduction to Apache Kafka](https://www.gentlydownthe.stream/)
* [Event Driven Architecture using Kafka | LinkedIn](https://www.linkedin.com/pulse/event-driven-architecture-using-kafka-kunal-mohanta/)
* [Kafka in the Wild • Laura Schornack & Maureen Penzenik • GOTO 2021 - YouTube](https://www.youtube.com/watch?v=iMx8otu3rFg) Domain Driven Design for Realtime, Ubiquitous, Distributed Data
* [How Agoda manages 1.5 Trillion Events per day on Kafka | by Shaun Sit | Agoda Engineering & Design | Jul, 2021 | Medium](https://medium.com/agoda-engineering/how-agoda-manages-1-5-trillion-events-per-day-on-kafka-f0a27fc32ecb)
* [Kafka 는 왜 빠를까? - 상구리의 기술 블로그](https://www.skyer9.pe.kr/wordpress/?p=3372)
* [Kafka 클러스터 구성 및 장애 해결 :: 당근케잌](https://yeon-kr.tistory.com/183)
* [Integrate Apache Kafka and SAP with the Kafka Connect ODP Source Connector](https://www.confluent.io/blog/kafka-sap-integration-with-kafka-connect-odp-source-connector/)
* [Logstash의 Kafka Input 성능 개선 이야기](https://alden-kang.tistory.com/24)
  * Logstash를 사용하면서 Kafka Lag가 급격히 증가하는 문제를 해결하기 위한 개선 과정 설명
  * 처음에는 파티션 수를 늘렸지만 해결되지 않아서 자세히 보니 파티션에 컨슈머가 고르게 붙어있지 않은 문제 발견
  * partition_assignment_strategy를 사용해서 라운드 로빈을 적용했으나 트래픽이 늘어나자 다시 Lag 증가
  * 그래서 Lag의 의미를 자세히 찾아보니 마지막에 생성된 메시지와 컨슈머가 가져갔다고 표시한 오프셋의 차이라는 것을 알게 되어 auto_commit_interval_ms를 5초에서 1초로 줄여서 La를 해결

## Kafka Library
* [aiokafka - asyncio client for kafka http://aiokafka.readthedocs.io ](https://github.com/aio-libs/aiokafka)
* [akhq: Kafka GUI for Apache Kafka to manage topics, topics data, consumers group, schema registry, connect and more...](https://github.com/tchiotludo/akhq)
  * [카프카 매니저를 대체할 수 있을까?! AKHQ (Apache Kafka HQ) :: 언제나 김김](https://always-kimkim.tistory.com/entry/Kafka-%EC%B9%B4%ED%94%84%EC%B9%B4-%EB%A7%A4%EB%8B%88%EC%A0%80%EB%A5%BC-%EB%8C%80%EC%B2%B4%ED%95%A0-%EC%88%98-%EC%9E%88%EC%9D%84%EA%B9%8C-AKHQ-Apache-Kafka-HQ)
* [burrow - Kafka Consumer Lag Checking](https://github.com/linkedin/Burrow)
  * [Burrow - kafka consumer의 지연(lag)을 모니터링할 수 있는 효과적인 opensource tool](https://blog.voidmainvoid.net/243)
  * [Revisiting Burrow: Burrow 1.1](https://engineering.linkedin.com/blog/2018/05/revisiting-burrow--burrow-1-1-) Linkedin의 SRE팀에서 만들어서 오픈소스로 공개한 Apache Kafka의 Consumer 모니터링 도구
  * [Apache Kafka Lag Monitoring and Metrics at AppsFlyer](https://www.confluent.io/blog/kafka-lag-monitoring-and-metrics-at-appsflyer/)
  * [kafka-lag-dashboard](https://github.com/AndersonChoi/kafka-lag-dashboard)
  * [kafka-lag-dashboard](https://blog.voidmainvoid.net/279)
* [Conduktor - the ultimate Apache Kafka Desktop Client](https://www.conduktor.io)
* [Cruise-control - the first of its kind to fully automate the dynamic workload rebalance and self-healing of a kafka cluster. It provides great value to Kafka users by simplifying the operation of Kafka clusters](https://github.com/linkedin/cruise-control)
* [Flafka: Apache Flume Meets Apache Kafka for Event Processing](http://blog.cloudera.com/blog/2014/11/flafka-apache-flume-meets-apache-kafka-for-event-processing/)
* [Greyhound - Rich Kafka client library](https://github.com/wix/greyhound)
  * [Kafka Cron using wix/greyhound. I think one of the best ways to learn… | by Algimantas Krasauskas | Wix Engineering | Dec, 2020 | Medium](https://medium.com/wix-engineering/kafka-cron-using-wix-greyhound-64c7b99a1c3e)
* hive
  * [Kafka Storage Handler Module](https://github.com/apache/hive/tree/master/kafka-handler)
* [kafka-docker: Dockerfile for Apache Kafka](https://github.com/vcho1958/kafka-docker)
* [Kafka Manager - A tool for managing Apache Kafka](https://github.com/yahoo/kafka-manager)
  * [hub.docker.com/r/sheepkiller/kafka-manager](https://hub.docker.com/r/sheepkiller/kafka-manager/)
  * [Kafka Manager Consumer Lag Exporter](https://github.com/thinker0/kafka-manager-consumer-lag-exporter)
  * 디테일하게 'Destionation Topic의 Partition별 offset' 을 보고 싶은 경우 Destination Topic을 모니터링 시스템에 연결하는 방식
* [kafka-monitor - Monitor the availability of Kafka clusters with generated messages](https://github.com/linkedin/kafka-monitor)
  * [URP? Excuse You! The Three Metrics You Have to Know (Todd Palino, Linkedin) Kafka Summit 2018](https://videos.confluent.io/watch/upUNYs7NAGN6jbQefwERFs)
* [Kafka Offset Monitor - an app to monitor your kafka consumers and their position (offset) in the queue](https://github.com/quantifind/KafkaOffsetMonitor)
* [Kafka-Sprout: Web GUI for Kafka Cluster Management](https://github.com/oslabs-beta/Kafka-Sprout)
* [kafka-statsd-metrics2](https://github.com/airbnb/kafka-statsd-metrics2)
* [kafka tools - A collection of tools for working with Apache Kafka](https://github.com/linkedin/kafka-tools)
* [Kafractive - interative CLI tool for kafka admin, built on top of Spring Shell](https://github.com/gnu-gnu/kafractive)
* [kowl: Kafka WebUI for exploring messages, consumers. configurations and more with a focus on a good UI & UX](https://github.com/cloudhut/kowl)
* [KubeMQ: A Modern Alternative to Kafka - DZone Microservices](https://dzone.com/articles/seamless-migration-from-kafka-to-kubemq)
* [librdkafka: The Apache Kafka C/C++ library](https://github.com/edenhill/librdkafka)
* MAADS [Machine Learning and AI at Scale with MAADS-VIPER and Apache Kafka](https://www.confluent.io/blog/transactional-machine-learning-with-maads-viper-and-apache-kafka/)
* rest proxy
  * [카프카의 토픽 데이터를 REST api로 주고받자 - Kafka rest proxy 사용](https://blog.voidmainvoid.net/345)
  * [Confluent REST Proxy 6.0: Putting Apache Kafka to REST](https://www.confluent.io/blog/confluent-rest-proxy-putting-kafka-to-rest/)
* [spring-kafka-example: Example source code for KafkaKRU meetup](https://github.com/gnu-gnu/spring-kafka-example)
* [Trifecta - a web-based and Command Line Interface (CLI) tool that enables users to quickly and easily inspect, verify and even query Kafka messages](https://github.com/ldaniels528/trifecta)
* [trivup - Trivially Up a cluster of applications](https://github.com/edenhill/trivup)
  * 프로그래밍 방식으로 카프카 클러스터를 구축하고 해체하는 도구. 클라이언트 응용 프로그램에 대한 Kafka의 SSL 인증 및 암호화 지원
* uGroup [Introducing uGroup: Uber’s Consumer Management Framework](https://eng.uber.com/introducing-ugroup-ubers-consumer-management-framework/)
* [zoe: The missing companion for Kafka](https://github.com/adevinta/zoe)

## Kafka Stream
* [카프카 스트림즈 All stream threads have died. 오류 해결 방안](https://voidmainvoid.tistory.com/437)
* [Kafka Streams examples](https://github.com/confluentinc/kafka-streams-examples)
* [REACTIVE STREAMS FOR APACHE KAFKA](https://softwaremill.com/reactive-kafka/)
* [This is a Kafka-Storm-Esper example on vagrant](https://github.com/doohee323/tzstorm)
  1. kafka를 사용할 때 Producer.send 해서 stream을 전달하던데, legacy시스템에서 별도의 코딩을 통해서 구현해야 하는 것인지 => kafka를 사용할 때 보통 producer, consumer를 구현한다. kafka - storm을 사용할 때 kafkaspout는 consumer 역할은 한다.
  2. KafkaSpout에서 생성된 stream이 storm의 Bolt로 들어올 때 어떻게 디버깅이 가능한 지 => 원격 디버깅은 없고 -Dstorm.log.dir를 통한 로그파일로 디버깅한다.
  3. bolt로 넘어온 중복된 stream을 어떻게 unique한 데이터로 처리 가능한 지 => unique한 데이터 처리를 위해서 trident를 사용하며, trident는 storm의 구현을 지원하는 (aggregation 등) 역할을 한다. -> esper로 group by 등의 쿼리문을 만들 수 있는데 trident와 역할 충돌이 있지 않을까 싶지만, trident를 통해 unique한 데이터를 받아 esper로 쿼리문을 돌릴 수 있지 않을까 싶다.
  4. kafka 대신에 zmq로 연동할 때 예상되는 문제점이 있는지. zmq와 kafka 모두 큐 역할을 하므로 특별한 이유가 없다면 zmqspout를 활용하는 것이 좋겠다.
* [stream-reactor Streaming reference architecture built around Kafka. http://datamountaineer.com/2016/01/12/streamliner ](https://github.com/datamountaineer/stream-reactor)
* [Distributed, Real-time Joins and Aggregations on User Activity Events using Kafka Streams](http://www.confluent.io/blog/distributed-real-time-joins-and-aggregations-on-user-activity-events-using-kafka-streams)
* [Tweeter: Processing Tweets with Kafka Streams](https://www.madewithtea.com/processing-tweets-with-kafka-streams.html)
* [내부 데이터 파이프라인에 Kafka Streams 적용하기](https://engineering.linecorp.com/ko/blog/detail/80)
  * [Line: Applying Kafka Streams for internal message delivery pipeline](https://engineering.linecorp.com/en/blog/detail/80)
* [Quick Recipe for #Kafka Streams in #Clojure](https://dataissexy.wordpress.com/2016/12/06/quick-recipe-for-kafka-streams-in-clojure/)
* [Perfecting Lambda Architecture with Oracle Data Integrator (and Kafka / MapR Streams)](https://www.mapr.com/blog/perfecting-lambda-architecture-oracle-data-integrator-and-kafka-mapr-streams)
  * MySQL 데이터베이스의 변경 내용을 스트림으로 캡처하기 위해 Oracle Data Integrator, Apache Kafka / MapR Stream를 구성하는 과정
* [Streaming databases in realtime with MySQL, Debezium, and Kafka](https://wecode.wepay.com/posts/streaming-databases-in-realtime-with-mysql-debezium-kafka)
  * WePay에서 Debezium을 사용하여 Kafka로 데이터를 스트리밍하는 MySQL용 데이터 캡처 솔루션을 사용하는 것에 대한 기사
* [Kafka + Spark-Streaming with Python으로 실시간 분석시스템 만들기](http://hellowuniverse.com/2017/04/26/kafka-spark-streaming-with-python%EC%9C%BC%EB%A1%9C-%EC%8B%A4%EC%8B%9C%EA%B0%84-%EB%B6%84%EC%84%9D%EC%8B%9C%EC%8A%A4%ED%85%9C-%EB%A7%8C%EB%93%A4%EA%B8%B0/)
* [Kafka + Spark-Streaming with Python으로 실시간 분석시스템 만들기(2)](http://hellowuniverse.com/2017/05/15/kafka-spark-streaming-with-python%EC%9C%BC%EB%A1%9C-%EC%8B%A4%EC%8B%9C%EA%B0%84-%EB%B6%84%EC%84%9D%EC%8B%9C%EC%8A%A4%ED%85%9C-%EB%A7%8C%EB%93%A4%EA%B8%B02/)
* [Reading data securely from Apache Kafka to Apache Spark](http://blog.cloudera.com/blog/2017/05/reading-data-securely-from-apache-kafka-to-apache-spark/)
  * Cloudera에서 최근 Kafka와 연계된 Spark 작업에 암호화 및 권한 부여를 제공하기 위해 Apache Kafka, Apache Spark, Apache Ranger를 통합
  * 이를 어떻게 구현하고 왜 이런 설계를 하게되었는지 설명
* [Kafka Connect vs StreamSets: advantages and disadvantages?](https://www.linkedin.com/pulse/kafka-connect-vs-streamsets-advantages-disadvantages-slim-baltagi)
  * Kafka Connect 및 StreamSets 데이터 수집기 비교 설명
* [Evolving Avro Schemas with Apache Kafka and StreamSets Data Collector](https://streamsets.com/blog/evolving-avro-schemas-apache-kafka-streamsets-data-collector/)
  * Streamsets의 Dataflow Performance Blog에 올라온 내용
  * Avro의 스키마 버번을 저장하기 위해 Confluent Schema Registry의 동기화에 대해 설명
  * Streamset의 데이터 수집기 도구를 사용하여 schema-aware producer를 사용하여 데이터를 serialize/deserialize 하는 방법 설명
* [Performance Tuning of an Apache Kafka/Spark Streaming System - Telecom Case Study](https://mapr.com/blog/performance-tuning-kafka-spark-streaming-telecom/)
  * Apache Kafka, Spark Streaming 및 Apache Ignite (RDD의 캐싱)와 관련된 실제 응용 프로그램의 성능 튜닝
  * Kafka 파티션 수 증가, RPC 시간 초과 설정 수정, Spark 및 Ignite 메모리 모두 조정, 일괄 처리 간격 수정 등
* [Build Services on a Backbone of Events](https://www.confluent.io/blog/build-services-backbone-events/)
  * Apache Kafka가 단순히 빠른 ETL보다 더 혁신적이고 좋다고 주장
  * 스트리밍, 응용 프로그램, 데이터베이스 간의 통합, ETL (중앙 집중식 모노리스가 아닌) 배포, 규모 및 안정성 등 Kafka가 제공하는 장점을 강조
* [High Performance Kafka Consumer for Spark Streaming. Now Support Spark 2.0 and Kafka 0.10](https://github.com/dibbhatt/kafka-spark-consumer)
* [Recent Evolution of Zero Data Loss Guarantee in Spark Streaming With Kafka](http://getindata.com/blog/post/recent-evolution-of-zero-data-loss-guarantee-in-spark-streaming-with-kafka/)
* [Spark Streaming + Kafka Integration Guide (Kafka broker version 0.10.0 or higher)](https://spark.apache.org/docs/latest/streaming-kafka-0-10-integration.html)
* [Getting Started with the Kafka Streams API using Confluent Docker Images](https://www.confluent.io/blog/getting-started-with-the-kafka-streams-api-using-confluent-docker-image/)
* [Real-time Financial Alerts at Rabobank with Apache Kafka’s Streams API](https://www.confluent.io/blog/real-time-financial-alerts-rabobank-apache-kafkas-streams-api/)
  * Rabobank가 메인 프레임에서 Apache Kafka(다중 데이터 센터 배포 및 Kafka Streams로 구축)로 고객 알림 시스템을 이동한 사례에 대해 설명
* [Real-Time Anomaly Detection Streaming Microservices with H2O and MapR – Part 1: Architecture](https://mapr.com/blog/real-time-anomaly-detection-1/)
  * IOT 센서 데이터를 스트리밍하여 비정상 상태를 감지하는 아키텍처에 대해 소개
* [Streaming Kafka Messages to MySQL Database](https://www.toadworld.com/platforms/oracle/w/wiki/11647.streaming-kafka-messages-to-mysql-database) flume과의 조합
* [Integrating Kafka and Spark Streaming: Code Examples and State of the Game](http://www.michael-noll.com/blog/2014/10/01/kafka-spark-streaming-integration-example-tutorial/)
* [Spark Streaming with Kafka and Cassandra](http://helenaedelson.com/?p=991)
* [Ranking Websites in Real-time with Apache Kafka’s Streams API](https://www.confluent.io/blog/ranking-websites-real-time-apache-kafkas-streams-api/)
  * 유럽 최대의 온라인 패션 소매 업체인 Zalando에서 Apache Kafka를 사용하여 패션 웹 사이트의 정보를 색인하고 순위를 매기는 방법에 대해 소개
  * 이 시스템은 HITS (Hyperlink Induced Topic Search) 알고리즘을 사용하며 Kafka 스트림이 기반
* [Using Kafka Streams API for predictive budgeting](https://medium.com/@Pinterest_Engineering/using-kafka-streams-api-for-predictive-budgeting-9f58d206c996)
* [lenses - a Streaming Data Management Platform for Apache Kafka](http://www.landoop.com/kafka-lenses/)
  * [How to explore data in Kafka topics with Lenses - part 1](http://www.landoop.com/blog/2017/11/lenses-how-to-view-kafka-topics-data/)
  * [stream-reactor - Streaming reference architecture for ETL with Kafka and Kafka-Connect. You can find more on http://landoop.com on how we provide a unified solution to manage your connectors, most advanced SQL engine for Kafka and Kafka Streams, cluster monitoring and alerting, and more http://www.landoop.com/kafka/connectors ](https://github.com/Landoop/stream-reactor)
* [Kafka & Redis Streams](https://medium.com/@timothy_downs/introduction-to-redis-streams-133f1c375cd3)
* [Enabling Exactly-Once in Kafka Streams](https://www.confluent.io/blog/enabling-exactly-kafka-streams/)
* [Migrating Batch ETL to Stream Processing: A Netflix Case Study with Kafka and Flink](https://www.infoq.com/articles/netflix-migrating-stream-processing)
  * QCon New York 2017에서 Netflix의 스트림 처리 시스템에 대해 소개한 내용을 설명
  * Apache Kafka, Apache Flink, Apache Mesos 등으로 구축
  * 비디오 재생 / 검색 이벤트의 데이터를 분석
  * Netflix가 직면한 도전 과제와 그것에 따라 구현된 전략에 대해서도 설명
* [Of Streams and Tables in Kafka and Stream Processing, Part 1](http://www.michael-noll.com/blog/2018/04/05/of-stream-and-tables-in-kafka-and-stream-processing-part1/) 스트림과 테이블에 대한 개념을 설명
* [Kafka streams Java application to aggregate messages using a session window](http://ericlondon.com/2018/07/26/kafka-streams-java-application-to-aggregate-messages-using-a-session-window.html) Java Kafka stream 기초 예제
* [Neha Narkhede | Kafka Summit 2017 Keynote (Go Against the Flow: Databases and Stream Processing)](https://www.youtube.com/watch?v=F3pJOg1uErQ) KSQL demo
* [Neha Narkhede | Kafka Summit 2018 Keynote (The Present and Future of the Streaming Platform) London](https://www.youtube.com/watch?v=eublKlalobg)
* [Kafka Summit London](https://www.confluent.io/resources/kafka-summit-london-2019)
* [Introducing Hortonworks Streams Messaging Manager (SMM)](https://ko.hortonworks.com/blog/introducing-hortonworks-streams-messaging-manager-smm/)
  * Apache Kafka 운영 관리 도구 & API
  * kafka의 4가지 엔티티(producer, topic, broker, consumers)에 대한 메트릭을 보여주고, 하나 이상의 (Secure) Kafka cluster에 대한 통합 플랫폼뿐만 아니라 각 클래스에 대해 REST API를 제공
  * 자사 개발 제품군인 Apache Atlas, Ranger, Ambari와 높은 호환성
* [Testing Kafka Streams Applications](https://speakerdeck.com/dongjin/testing-kafka-streams-applications)
* [Kafka Streams for Stream processing A few words about how Kafka works](https://balamaci.ro/kafka-streams-for-stream-processing/)
* [Building Secure and Governed Microservices with Kafka Streams](https://ko.hortonworks.com/blog/building-secure-and-governed-microservices-with-kafka-streams/)
  * 트럭 화물 운송회사에서 지오-이벤트 센서 데이터를 캡처하고 분석할 수 있는 애플리케이션을 Kafka Streams로 만드는 방법
* [Learn kafka streams by making the tests pass](https://github.com/ardlema/kafka-streams-workshop)
  * Apache Kafka Streams를 배울 수 있는 워크숍
* [Apache Kafka leaves the Zoo](https://medium.com/@lukasz.antoniak/apache-kafka-leaves-the-zoo-bef529ba82b7)
* [Using Graph Processing for Kafka Stream Visualizations](https://www.confluent.io/blog/kafka-graph-visualizations<Paste>))
* [Making sense of Avro, Kafka, Schema Registry, and Spark Streaming](https://medium.com/@ivan9miller/making-sense-of-avro-kafka-schema-registry-and-spark-streaming-bbb09eb5039c)
* [Kafka Spark Streaming Integration in java from scratch | Code walk through - YouTube](https://www.youtube.com/watch?v=UcWi3-FODjs)
* [Streaming the last few minutes from Kafka using Akka Streams](https://medium.com/wbaa/streaming-the-last-few-minutes-from-kafka-using-akka-streams-dfa2ecd1fdbb)
* [How to Test Kafka Streams Applications](https://medium.com/better-programming/testing-kafka-streams-applications-1c5cb14c5376)
* [Streaming With Probabilistic Data Structures: Why & How | by Eliav Lavi | Riskified Technology | Oct, 2020 | Medium](https://medium.com/riskified-technology/streaming-with-probabilistic-data-structures-why-how-b83b2adcd5d4)
* [Batch to Real-Time Streams: 8 Years of Event Streaming with Apache Kafka](https://www.confluent.io/blog/batch-to-streams-8-years-of-event-streaming-with-apache-kafka/)
* [카프카 스트림즈 Exactly-once 설정하는 방법과 내부 동작](https://voidmainvoid.tistory.com/438)
* [카프카 스트림즈! 대용량, 폭발적인 성능의 실시간 데이터 처리! - YouTube](https://www.youtube.com/watch?v=vKxhPUUEDmM)
* [카프카 스트림즈에서 stateful window 처리를 다루는 방법 그리고 커밋타이밍](https://voidmainvoid.tistory.com/452)
* [Kafka Streams 101 - Rock the JVM Blog](https://blog.rockthejvm.com/kafka-streams/)
* [brooklin - An extensible distributed system for reliable nearline data streaming at scale](https://github.com/linkedin/Brooklin/)
  * [Open Sourcing Brooklin: Near Real-Time Data Streaming at Scale](https://engineering.linkedin.com/blog/2019/brooklin-open-source)
  * Kafka Connect + MirrorMaker의 대안으로 개발된 범용 Framework. Scalable할 뿐만 아니라 Kafka 외에도 다양한 Storage / Streaming System 지원
  * 자체적인 Cluster를 설정해야 하며, 2019.07에 공개되어 자료 전무
  * monitoring 방법은 MirrorMaker 1/2와 마찬가지로 내부적으로 kafka producer를 사용해 해당 process에 jmx로 접속해 producer sender metrics를 확인
* [Debezium - Stream changes from your database](https://debezium.io)
  * [debezium: Change data capture for a variety of databases. Please log issues at https://issues.redhat.com/browse/DBZ. ](https://github.com/debezium/debezium)
  * [How Debezium & Kafka Streams Can Help You Write CDC Solution](https://iamninad.com/how-debezium-kafka-stream-can-help-you-write-cdc/) Debezium과 Kafka를 사용하여 MySQL과 MongoDB에서 쓰여진 데이터를 캡처하는 플랫폼을 설정하는 방법
  * [DevNation Live: Kafka and Debezium](https://www.slideshare.net/RedHatDevelopers/devnation-live-kafka-and-debezium)
  * [Change Data Streaming Patterns for Microservices with Debezium](https://developers.redhat.com/videos/youtube/QYbXDp4Vu-8)
  * [Using Debezium, CDC for Apache Kafka, with PostgreSQL and MongoDB – Flant blog](https://blog.flant.com/debezium-cdc-for-apache-kafka/)
  * [Practical Change Data Streaming Use Cases with Apache Kafka & Debezium](https://www.infoq.com/presentations/data-streaming-kafka-debezium/)
* Decaton [Kafka를 이용한 작업 큐 라이브러리 'Decaton' 활용 사례 - LINE ENGINEERING](https://engineering.linecorp.com/ko/blog/decaton-case-studies/)
* kafka connect
  * [Kafka Connect S3 Source Connector](https://docs.confluent.io/current/connect/kafka-connect-s3-source/index.html)
  * [Presto Kafka connector 개선 실패기](http://www.popit.kr/presto-kafka-connector-%EA%B0%9C%EC%84%A0-%EC%8B%A4%ED%8C%A8%EA%B8%B0/)
  * [Splunking Kafka with Kafka Connect](https://lilgreenwein.com/2017/02/16/splunking-kafka-with-kafka-connect/)
    * Kafka에서 Splunk로 데이터를 전송하기 위한 새로운 Kafka Connect 플러그인을 설명(아키텍처 및 디자인 선택 포함)
    * Kafka Connect를 설정하여 Kafka topic을 Splunk Heavy Forwarder로 데이터를 스트리밍하는 튜토리얼 포함
  * The Simplest Useful Kafka Connect Data Pipeline In The World … or Thereabouts
    * [Part 1](https://www.confluent.io/blog/simplest-useful-kafka-connect-data-pipeline-world-thereabouts-part-1/)
      * RDBMS (이 경우 MySQL)에서 변경 데이터 캡처를 위해 Apache Kafka Connect를 사용하는 방법을 예제를 통해 설명
    * [Part 2](https://www.confluent.io/blog/blogthe-simplest-useful-kafka-connect-data-pipeline-in-the-world-or-thereabouts-part-2/)
    * [Part 3](https://www.confluent.io/blog/simplest-useful-kafka-connect-data-pipeline-world-thereabouts-part-3/)
  * [Getting started with the Kafka Connect Cassandra Source](https://medium.com/walmartlabs/getting-started-with-the-kafka-connect-cassandra-source-e6e06ec72e97) Ladoop 에서 제공하고 있는 Cassandra Source Connector 사용하여 Kafka로 스트리밍을 설정하는 방법 소개
  * [Connecting Kafka to MinIO. How to connect data being distributed… | by Alex | The Startup | Medium](https://medium.com/swlh/connecting-kafka-to-a-minio-s3-bucket-using-kafka-connect-92d34a81704e)
  * [How to Write a Kafka Connector with Proper Configuration Handling](https://www.confluent.io/blog/write-a-kafka-connect-connector-with-configuration-handling/)
  * [kafka-connect-datagen: Connector that generates data for demos](https://github.com/confluentinc/kafka-connect-datagen)
    * [kafka-connect-datagen 커넥터로 테스트 데이터 생성하기](https://always-kimkim.tistory.com/entry/kafka-develop-kafka-connect-datagen)
  * [Alpakka Kafka connector - Alpakka is a Reactive Enterprise Integration library for Java and Scala, based on Reactive Streams and Akka](https://github.com/akka/alpakka-kafka)
    * [Alpakka Kafka connector — an open-source Reactive Enterprise Integration library for Java and Scala](https://blog.softwaremill.com/alpakka-kafka-connector-an-open-source-reactive-enterprise-integration-library-for-java-and-scala-c5f954b66787)
    * [Retrying consumer architecture with Alpakkas](https://medium.com/@gabrielgiussi/retrying-consumer-architecture-with-alpakkas-ebd24eda1982)
  * MirrorMaker2 [kafka/connect/mirror at trunk · apache/kafka](https://github.com/apache/kafka/tree/trunk/connect/mirror)
    * [How to run Kafka Mirror Maker using Kerberos clusters](https://www.youtube.com/watch?v=2jkk3ZycW78)
    * [MirrorMaker Performance Tuning Tuning Kafka for Cross Data Center Replication](https://engineering.salesforce.com/mirrormaker-performance-tuning-63afaed12c21)
      * compression.type 지정
      * Producer 에서 사용하면, Network BW 및 Broker단의 CPU 절약
      * 전통적으로 Kafka 프로젝트 안에 탑재되어 있던 툴이지만 설계가 오래되서 scalable하게 동작하지 않으므로, 어지간히 오래된 Cluster 내용을 옮기는 게 아니라면 비추천
    * [Kafka Replication: The case for MirrorMaker 2.0](https://blog.cloudera.com/blog/2019/05/kafka-replication-the-case-for-mirrormaker-2/)
      * MirrorMaker 1의 대안으로 Cloudera 엔지니어가 개발. 1보다 훨씬 좋지만 아직 정식 탑재된 게 아니라 문서화 부족
    * [MirrorMaker2 가 release되었습니다](https://blog.voidmainvoid.net/293)
    * [MirrorMaker2 마이그레이션](https://devidea.tistory.com/107)
* [kafka-streams-viz - Kafka Streams Topology Visualizer](https://zz85.github.io/kafka-streams-viz/)
* KSQL
  * [Introducing KSQL: Open Source Streaming SQL for Apache Kafka](https://www.confluent.io/blog/ksql-open-source-streaming-sql-for-apache-kafka/)
    * spark streaming의 대체?
    * Apache Kafka에서 SQL을 사용할 수 있는 인터페이스를 제공
  * [Getting Started Analyzing Twitter Data in Apache Kafka through KSQL](https://www.confluent.io/blog/using-ksql-to-analyse-query-and-transform-data-in-kafka)
    * 트위터의 스트리밍 데이터를 KSQL의 술어(predicate)로 필터링하고 시간당 사용자당 트윗 수를 계산하는 등 집계를 작성하는 예제
  * [KSQL: Streaming SQL for Apache Kafka](https://www.rittmanmead.com/blog/2017/10/ksql-streaming-sql-for-apache-kafka/)
  * [Taking KSQL for a Spin Using Real-time Device Data](https://www.rittmanmead.com/blog/2017/11/taking-ksql-for-a-spin-using-real-time-device-data/)
    * KSQL을 사용하여 간단한 스트리밍 프로그램을 보여주는 포스트
    * 입력이 드라이빙 게임 핸들의 디지털 센서 데이터 스트림
  * [Building a Microservices Ecosystem with Kafka Streams and KSQL](https://www.confluent.io/blog/building-a-microservices-ecosystem-with-kafka-streams-and-ksql/)
    * 카프카 스트림을 이용한 동기식 트랜잭션 시스템을 구축하는 예제
    * 사이드카 패턴을 통해 비 JVM 언어에 대해 패턴을 구현하기 위해 KSQL을 사용하는 개념 언급
  * [KSQL January release: Streaming SQL for Apache Kafka](https://www.confluent.io/blog/ksql-january-release-streaming-sql-apache-kafka/)
  * [How to Write a User Defined Function (UDF) for KSQL](https://www.confluent.io/blog/write-user-defined-function-udf-ksql/)
    * 아직 사용자 정의 함수(UDFs)의 런타임 구성을 지원하지 않지만 사용자 함수를 작성하고 빌드 가능
  * [KSQL in Action: Real-Time Streaming ETL from Oracle Transactional Data](https://www.confluent.io/blog/ksql-in-action-real-time-streaming-etl-from-oracle-transactional-data)
  * [Secure Stream Processing with Apache Kafka, Confluent Platform and KSQL](https://www.confluent.io/blog/secure-stream-processing-apache-kafka-ksql/)
  * We ❤ syslogs: Real-time syslog Processing with Apache Kafka and KSQL
    * [Part 1: Filtering](https://www.confluent.io/blog/real-time-syslog-processing-apache-kafka-ksql-part-1-filtering) Syslog Apache Kafka Connect plugin을 사용하여 Avro log 형식으로 Kafka로 가져온 후 KSQL을 사용하여 분석하는 방법을 설명
    * [Part 2: Event-Driven Alerting with Slack](https://www.confluent.io/blog/real-time-syslog-processing-with-apache-kafka-and-ksql-part-2-event-driven-alerting-with-slack/)
    * [Part 3: Enriching events with external data](https://www.confluent.io/blog/real-time-syslog-processing-apache-kafka-ksql-enriching-events-with-external-data/)
      * MongoDB 데이터를 결합하여 Apache Kafka의 syslog 데이터에 KSQL을 사용하여 스트리밍 응용프로그램을 구축하는 과정 설명
      * 알림은 Slack, 시각화 도구는 ES
  * [How to Build a UDF and/or UDAF in KSQL 5.0](https://www.confluent.io/blog/build-udf-udaf-ksql-5-0) KSQL 5.0에서 사용자 정의 집계 함수를 사용하는 방법
  * [ATM Fraud Detection with Apache Kafka and KSQL](https://www.confluent.io/blog/atm-fraud-detection-apache-kafka-ksql)
    * [ATM Fraud Detection with Kafka and KSQL - Hands on Guide](https://github.com/confluentinc/demo-scene/blob/master/ksql-atm-fraud-detection/ksql-atm-fraud-detection-README.adoc)
  * [Real-Time Sysmon Processing via KSQL and HELK — Part 1: Initial Integration](https://posts.specterops.io/real-time-sysmon-processing-via-ksql-and-helk-part-1-initial-integration-88c2b6eac839)
    * HELK; 보안 이벤트 로그를 분석하기 위해 표준 ELK를 확장한 스택
    * 이 글에서는 KSQL을 통해 추가 분석을 하는 방법을 설명
  * [Machine learning & Kafka KSQL stream processing — bug me when I’ve left the heater on](https://medium.com/@simon.aubury/machine-learning-kafka-ksql-stream-processing-bug-me-when-ive-left-the-heater-on-bd47540cd1e8)
  * [아파치 카프카 테스트용 data generator 소개 - ksql-datagen](https://blog.voidmainvoid.net/269)
  * [KSQL - 효과적이고 간단한 스트리밍 프로세스 SQL엔진](https://www.slideshare.net/WonyoungChoi2/ksql-sql-182725060)
  * [ksqlDB - The event streaming database purpose-built for stream processing applications](https://ksqldb.io/)
    * [How Real-Time Stream Processing Safely Scales with ksqlDB](https://www.confluent.io/blog/how-real-time-stream-processing-safely-scales-with-ksqldb/)
* [mockedstreams - Scala DSL for Unit-Testing Processing Topologies in Kafka Streams](https://github.com/jpzk/mockedstreams)

# Kudu
* [Kudu](http://kudu.apache.org/)
* [Kudu](http://blog.cloudera.com/blog/2015/09/kudu-new-apache-hadoop-storage-for-fast-analytics-on-fast-data/)
* [getkudu.io](http://getkudu.io/)
* [Kudu: New Hadoop Storage for Fast Analytics on Fast Data](http://www.slideshare.net/cloudera/kudu-new-hadoop-storage-for-fast-analytics-on-fast-data)
* [Apache Kudu as a More Flexible And Reliable Kafka-style Queue](http://blog.rodeo.io/2016/01/24/kudu-as-a-more-flexible-kafka.html)
* [Big Data: current trends & next big thing 'Apache Kudu' - my takeaways from Strata + Hadoop 2016 @San Jose](https://www.linkedin.com/pulse/notes-strata-hadoop-2016-san-jose-shenghu-hugo-yang)
* [#bbuzz 2016: Todd Lipcon - Apache Kudu (incubating): Fast Analytics on Fast Data](https://www.youtube.com/watch?v=z3rApSRXNMw)
* [Build a Prediction Engine Using Spark, Kudu, and Impala](https://dzone.com/articles/how-to-build-a-prediction-engine-using-spark-kudu)
* [Creating a Post-Lambda World with Apache Kudu](http://vision.cloudera.com/creating-a-post-lambda-world-with-apache-kudu/)
* [Up and running with Apache Spark on Apache Kudu](http://blog.cloudera.com/blog/2017/02/up-and-running-with-apache-spark-on-apache-kudu/)
* [Apache Kudu 1.3.0 was released](http://kudu.apache.org/releases/1.3.0/docs/release_notes.html)
  * Apache Kudu 1.3.0 릴리즈
  * Kerberos 인증, TLS를 사용한 암호화 전송, coarse-grained authorization 등 새로운 기능 추가
  * LZ4 압축으로 전환하는 등 몇 가지 최적화 기능 포함
* [Apache Kudu Read & Write Paths](http://blog.cloudera.com/blog/2017/04/apache-kudu-read-write-paths/)
* kudu-master clustering

  ```
  kudu-master \
    --master_addresses=172.23.30.101,172.23.30.102,172.23.30.103 \
    --fs_data_dirs=/data1/kudu/master/data \
    --fs_wal_dir=/data1/kudu/master/wal \
    --log_dir=/opt/log/kudu \
    --raft_get_node_instance_timeout_ms=60000
  ```
  * 위와 같이 3대에 띄우면, /data1/kudu/master/data 하위에 consensus를 맞추고 리더가 선출된 후에 별도의 000000000000000000 파일을 생성
  * 성공적으로 띄워지고 난 후로는 클러스터 노드가 깨져도 다시 띄울때 오류가 발생하지 않음
  * 오류 발생하였을 때는, /data1/kudu/master/data 와 /data1/kudu/master/wal 디렉토리 삭제후 다시 raft_get_node_instance_timeout_ms 내에 클러스터를 이루는 IP에 프로세스가 실행되도록 하면 됨
* [Low latency high throughput streaming using Apache Apex and Apache Kudu](https://www.slideshare.net/Hadoop_Summit/low-latency-high-throughput-streaming-using-apache-apex-and-apache-kudu)
  * Apache Kudu와 Apache Apex를 이용한 고성능 스트리밍처리 방식에 대해 설명
* [A brave new world in mutable big data relational storage (Strata NYC 2017)](https://www.slideshare.net/ToddLipcon/a-brave-new-world-in-mutable-big-data-relational-storage-strata-nyc-2017)
* [**Kudu를 이용한 빅데이터 다차원 분석 시스템 개발**](http://d2.naver.com/helloworld/9099561)
* [Guide to Using Apache Kudu and Performance Comparison with HDFS](https://blog.clairvoyantsoft.com/guide-to-using-apache-kudu-and-performance-comparison-with-hdfs-453c4b26554f)
* [Transparent Hierarchical Storage Management with Apache Kudu and Impala](https://blog.cloudera.com/blog/2019/03/transparent-hierarchical-storage-management-with-apache-kudu-and-impala)
  * Apache Kudu 및 Impala를 사용한 계층적 스토리지 관리
  * Apache Impala를 Apache Kudu 및 Apache HDFS에 저장된 데이터와 함께 사용하는 슬라이딩 윈도우(sliding window) 패턴
  * 이러한 패턴을 사용하면 여러 스토리지 계층의 이점을 사용자에게 투명한 방식으로 모두 구현 가능
  * Apache Kudu는 급변하는 데이터를 빠르게 분석할 수 있도록 설계. 또한 빠른 인서트/업데이트와 효율적인 열 기반 스캔을 결합하여 단일 스토리지 계층에서도 다수의 실시간 분석 워크로드를 지원. 이러한 이유 때문에 언제든지 쿼리를 실행할 수 있는 실시간 데이터가 저장되는 장소로서 데이터 파이프라인에 매우 적합. 또한 행 업데이트와 행 삭제를 실시간으로 지원하여 지연 수신되는 데이터 및 데이터 교정도 가능
  * Apache HDFS는 낮은 비용으로 무제한 확장이 가능하도록 설계. 따라서 데이터 변경이 불가능한 배치 지향 사용 사례에 최적화. 그 밖에도 Apache Parquet 파일 형식과 연결할 경우 매우 높은 처리량과 효율성으로 정형 데이터에 액세스 가능
  * 차원 테이블처럼 데이터가 소량이면서 끊임없이 바뀌는 상황에서는 모든 데이터를 Kudu에 저장하는 경우 다수. 데이터가 Kudu의 확장 제한을 넘지 않는다면 대용량 테이블이라고 해도 Kudu의 고유 기능을 이용 가능하므로 Kudu에 저장. 데이터가 대용량이고, 배치 지향적이고, 변경이 불가능한 경우에는 Parquet 형식을 사용해 데이터를 HDFS에 저장하는 것이 좋음. 두 스토리지 계층의 이점이 모두 요하다면 슬라이딩 윈도우 패턴이 효과적인 솔루션
* [Testing Apache Kudu Applications on the JVM](https://blog.cloudera.com/blog/2019/03/testing-apache-kudu-applications-on-the-jvm/)
* [Kudu as Storage Layer to Digitize Credit Processes](https://dataworkssummit.com/barcelona-2019/session/kudu-as-storage-layer-to-digitize-credit-processes/)

# Kylin
* [Kylin](http://kylin.apache.org/) Extreme OLAP Engine for Big Data
* [**빅데이터 다차원 분석 플랫폼, Kylin**](http://d2.naver.com/helloworld/1057065)
* [Apache Kylin 2.2.0 is released](https://kylin.apache.org/docs21/release_notes.html)
  * Apache Ranger를 사용하여 테이블 레벨에서 ACL을 관리하는 기능 등이 탑재
* [Using Hue to interact with Apache Kylin in your cluster or on AWS](http://gethue.com/using-hue-to-interact-with-apache-kylin/) Hue에서 JDBC 드라이버를 통해 Apache Kylin을 조회할 수 있는 방법을 설명합니다. AWS EMR 포함

# Kyuubi
* [Kyuubi Project Incubation Status - Apache Incubator](https://incubator.apache.org/projects/kyuubi.html)
  * distributed multi-tenant Thrift JDBC/ODBC server for large-scale data management, processing, and analytics, built on top of Apache Spark and designed to support more engines (i.e., Apache Flink)

# Mesos
* [Mesos](http://mesos.apache.org/)
* [Advanced Mesos Course](http://open.mesosphere.com/intro-course/)
* [Spark(1.2.1 -> 1.3.1) 을 위한 Mesos(0.18 -> 0.22.rc) - Upgrade](http://hoondongkim.blogspot.kr/2015/05/spark121-131-mesos018-021-upgrade.html)
* [mesos, omega, borg: a survey](http://www.umbrant.com/blog/2015/mesos_omega_borg_survey.html)
* [Mesos: A Platform for Fine-Grained Resource Sharing in the Data Center](http://people.csail.mit.edu/matei/papers/2011/nsdi_mesos.pdf)
* [minmesos - Testing infrastructure for Mesos frameworks](http://minimesos.org/)
* [메소스(mesos) 공부](http://knight76.tistory.com/entry/%EB%A9%94%EC%86%8C%EC%8A%A4-%EA%B0%84%EB%8B%A8-%EC%A0%95%EB%A6%AC)

# Metron
* [Metron](http://metron.apache.org) 보안에 포커스를 둔 분석 시스템

# Nifi
* [Nifi](https://nifi.apache.org/) Apache nifi is an easy to use, powerful, and reliable system to process and distribute data
* [NiFi를 이용한 빅데이터 플랫폼 개선](http://www.popit.kr/bigdata-platform-based-on-nifi/)
* [NSA의 Dataflow 엔진 Apache NiFi 소개와 설치](http://www.popit.kr/apache-nifi-overview-and-install/)
* [NiFi vs Falcon vs Oozie](https://www.linkedin.com/pulse/nifi-vs-falcon-oozie-birender-saini)
* [NiFi 소개 발표 자료](http://www.popit.kr/nifi-%EC%86%8C%EA%B0%9C-%EB%B0%9C%ED%91%9C-%EC%9E%90%EB%A3%8C/)
* [Introduction to Apache NiFi and Storm](https://speakerdeck.com/heartsavior/introduction-to-apache-nifi-and-storm)
* [Apache NiFi 1.x Cheatsheet](https://dzone.com/articles/apache-nifi-10-cheatsheet)
  * Apache NiFi에는 많은 Processor가 있어 어떤 Processor를 사용해야 할 지 찾아야 하는 경우가 많은데, 많이 사용하는 Processor를 소개
  * NiFi의 Rest API에 대해서도 설명
* [NiFi User Interface Overview](https://www.youtube.com/watch?v=Y5znvcJ_NWo)
* 실시간 Kafka consumer cluster를 구성하니
  * 구동속도 빠르고, 모니터링 편하고, 복잡한 transform GUI로 관리하고, partitioning도 알아서 한다는 글을 봤음
  * 간단한 작업에도 적합할까?
* [Apache NiFi 소개 및 Tensorflow 연동](https://www.facebook.com/nextobe1/posts/337425993360069)
* [HORTONWORKS DATAFLOW (HDF) 3.1 BLOG SERIES PART 5: INTRODUCING APACHE NIFI-ATLAS INTEGRATION](https://ko.hortonworks.com/blog/hdf-3-1-blog-series-part-6-introducing-nifi-atlas-integration/) Apache NiFi와 Apache Atlas를 Hortonwork DataFlow에 통합하여 Kafka, Hive 등의 데이터를 추적하는 방법을 간략하게 설명
* [What’s new in Hortonworks DataFlow (HDF) 3.2?](https://ko.hortonworks.com/blog/whats-new-hortonworks-dataflow-hdf-3-2/)
* [Best practices for using Apache NiFi in real world projects - 3 takeaways](https://medium.com/@abdelkrim.hadjidj/best-practices-for-using-apache-nifi-in-real-world-projects-3-takeaways-1fe6912101db)
  * PoC에서 프로덕션 환경 적용까지 필요한 사례 소개
* [Building an IIoT system using Apache NiFi, MiNiFi, C2 Server, MQTT and Raspberry Pi](https://medium.com/@abdelkrim.hadjidj/building-an-iiot-system-using-apache-nifi-mqtt-and-raspberry-pi-ce1d6ed565bc) IoT에서 Apache NiFi를 활용하는 예
* [HDF/HDP Twitter Sentiment Analysis End-to-End Solution](https://community.hortonworks.com/articles/208667/hdphdp-twitter-nlp-processing-framework.html)
* [IoT with Apache MXNet and Apache NiFi and MiniFi](https://www.youtube.com/watch?v=5w6rV7562xM)
* [Introduction to Apache NiFi dws19 DWS - DC 2019](https://www.slideshare.net/bunkertor/introduction-to-apache-nifi-dws19-dws-dc-2019)
* [Using Apache NiFi for Speech Processing: Speech to Text with Mozilla/Baidu's Deep Search in Tensorflow](https://community.hortonworks.com/articles/229305/using-apache-nifi-for-speech-processing-speech-to.html?es_p=9430533)
* [NiFi & NiFi Registry on the Google Cloud Platform with Cloud Source Repositories](https://pierrevillard.com/2019/07/02/nifi-and-nifi-registry-on-the-google-cloud-platform-with-cloud-source-repositories/)
* [**Building Data Pipelines on Apache NiFi with Python**](https://speakerdeck.com/sucitw/building-data-pipelines-on-apache-nifi-with-python) introduction인데 내용이 정말 풍부함
* [How Apache Nifi works — surf on your dataflow, don’t drown in it](https://medium.com/free-code-camp/nifi-surf-on-your-dataflow-4f3343c50aa2)
* [Processing one billion events per second with NiFi](https://blog.cloudera.com/benchmarking-nifi-performance-and-scalability/)
  * [Importing RDBMS Data Into Hive Using NiFi on CDP Public Cloud](https://www.youtube.com/watch?v=XsL63ZQYmLE)

# Nutch
* [Nutch](http://nutch.apache.org/)
* [Apache Nutch - 오픈소스 웹 검색 엔진](http://jsonlee.tistory.com/entry/Apache-Nutch-%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4-%EC%9B%B9-%EA%B2%80%EC%83%89-%EC%97%94%EC%A7%84)

# Oozie
* [Oozie](http://oozie.apache.org/)
* [How-to: Use the New Apache Oozie Database Migration Tool](http://blog.cloudera.com/blog/2016/11/how-to-use-the-new-apache-oozie-database-migration-tool/)
* [Jailbreak Oozie Spark action](https://medium.com/@ylashin/jailbreak-oozie-spark-action-c19d27bf85e2)

# Ozone
* [Introducing Apache Hadoop Ozone: An Object Store for Apache Hadoop](https://ko.hortonworks.com/blog/introducing-apache-hadoop-ozone-object-store-apache-hadoop/)
  * Apache Hadoop Ozone 소개. 하둡 저장소 레이어 최상단. 얼마 전 알파 버전 릴리즈
  * 기본 컨셉
    * SCALABLE
      * Ozone is designed to scale to tens of billions of files and blocks and, in the future, even more
      * Small files or huge number of datanodes are no longer a limitation
    * CONSISTENT; Storage Layer uses RAFT protocol for consistentency
    * CLOUD-NATIVE; Hadoop Ozone is designed to work well in containerized environments like YARN and Kubernetes
* [Apache Hadoop Ozone – Object Store Architecture](https://ko.hortonworks.com/blog/apache-hadoop-ozone-object-store-architecture/)
* [One billion files in Ozone](https://blog.cloudera.com/one-billion-files-in-ozone/)

# Parquet
* [Parquet](https://parquet.apache.org/)
* [Using Apache Parquet at AppNexus](http://blog.cloudera.com/blog/2015/04/using-apache-parquet-at-appnexus/)
* [Dremel made simple with Parquet](https://blog.twitter.com/2013/dremel-made-simple-with-parquet)
* [Benchmarking Apache Parquet: The Allstate Experience](http://blog.cloudera.com/blog/2016/04/benchmarking-apache-parquet-the-allstate-experience/)
* [fastparquet - A Python interface to the Parquet file format](https://fastparquet.readthedocs.io)
* [Sorting and Parquet](https://medium.com/@pankajroark/sorting-and-parquet-3a382893cde5)
  * Apache Parquet로 직렬화하기 전에 데이터를 정렬하면 쿼리 성능이 크게 달라질 수 있음
  * 이 글에서는 그 이유를 설명하고 정렬할 column을 파악하는 방법에 대한 아이디어 제공
* [**Parquet Internal Part 1. Google Dremel(1)**](https://medium.com/@leeyh0216/parquet-internal-part-1-google-dremel-1-3b95e1136a05)

# Phoenix
* [Phoenix](http://phoenix.apache.org/) High performance relational database layer over HBase for low latency applications
* [Apache Phoenix Joins Cloudera Labs](http://blog.cloudera.com/blog/2015/05/apache-phoenix-joins-cloudera-labs/)
* [Apache Phoenix: Use Cases and New Features](http://www.slideshare.net/HBaseCon/apache-phoenix-use-cases-and-new-features)
  * HBase + Phoenix를 활용하여 Timeseries DB로 사용하도록 하는 Argus, ACID Transaction 이 가능케 하는 Apache Tephra, Cost bases Query Optimizer인 Apache Calite 활용 사례 소개
* [The Apache Software Foundation: Column Mapping and Immutable Data Encoding of Apach Phoenix 4.1](https://blogs.apache.org/phoenix/entry/column-mapping-and-immutable-data)
  * Apache Phoenix 4.10 릴리즈
  * 새로운 기능인 컬럼 매핑과 변경 불가 데이터 인코딩 기능을 소개
  * TPC-H benchmark상으로 속도 향상 및 공간 절약 효과가 상당
* [Apache Spark Plugin](https://phoenix.apache.org/phoenix_spark.html)
* [3 Steps for Bulk Loading 1M Records in 20 Seconds Into Apache Phoenix](https://medium.com/hashmapinc/3-steps-for-bulk-loading-1m-records-in-20-seconds-into-apache-phoenix-99b77ad87387) Apache Spark를 사용하여 Apache HBase 및 Apache Phoenix와 호환하는 HFile을 생성하는 방법 설명
* [Apache Phoenix for CDH](https://www.cloudera.com/downloads/phoenix.html)
  * [Apache Phoenix for CDH](https://blog.cloudera.com/blog/2019/07/apache-phoenix-for-cdh)

# Pig
* [Pig](http://pig.apache.org/)
* [A Simple Explanation of COGROUP in Apache Pig](http://joshualande.com/cogroup-in-pig/)
* [practice - gist.github.com/hyunjun/55f83bfd91e2b1e24f46](https://gist.github.com/hyunjun/55f83bfd91e2b1e24f46)
* [hug number of part files](https://github.com/dsindex/blog/wiki/%5Bpig%5D-hug-number-of-part-files)
* [Hadoop Tutorial: Pig Part 2 -- Joining Data Sets and Other Advanced Topics](http://www.slideshare.net/martyhall/hadoop-tutorial-pig-part-2-joining-data-sets-and-other-advanced-topics)
* [Hadoop Pig Tutorial](https://medium.com/@ananthis740/hadoop-pig-tutorial-7f3b827b25cb)

# Pinot
* [Apache Pinot™ (Incubating): Realtime distributed OLAP datastore | Apache Pinot™ (Incubating)](https://pinot.apache.org/)
* [Introducing Apache Pinot 0.5.0. We are excited to announce that Apache… | by Ting Chen | Apache Pinot Developer Blog | Sep, 2020 | Medium](https://medium.com/apache-pinot-developer-blog/introducing-apache-pinot-0-5-0-e27983b6a678)
* [Intro to Apache Pinot - YouTube](https://www.youtube.com/watch?v=T70jTTYhYyM)

# PredictionIO
* [PredictionIO](http://predictionio.incubator.apache.org/)
* [incubator-predictionio - PredictionIO, a machine learning server for developers and ML engineers. Built on Apache Spark, HBase and Spray. http://prediction.io ](https://github.com/apache/incubator-predictionio)

# Pulsar
* [Apache Pulsar](https://pulsar.apache.org/) 기존의 메시징/스트리밍 시스템의 단점을 보완하기 위해 Yahoo에서 시작된 분산형 pub-sub 시스템
* Geo-replication in Apache Pulsar
  * [part 1: concepts and features](https://streaml.io/blog/apache-pulsar-geo-replication)
  * [part 2: patterns and practices](https://streaml.io/blog/geo-replication-patterns-practices)
  * Apache Pulsar를 사용하여 cross-data center replication를 수행하는 방법에 대해 설명
  * 복제를 설정하는 데 필요한 명령, 응용 프로그램별로 재정의하는 방법, 모니터링 방법, 복제 대역폭을 제한하는 방법 등에 대해 설명
* [Comparing Pulsar and Kafka: how a segment-based architecture delivers better performance, scalability, and resilience](https://streaml.io/blog/pulsar-segment-based-architecture)
* [Querying Data Streams with Apache Pulsar SQL](https://streaml.io/blog/querying-data-streams-with-apache-pulsar-sql)
  * Apache Pulsar를 통해 스트리밍 데이터를 SQL로 조회하는 아키텍처, 성능, 리뷰 포함
* [Apache Pulsar. MacOS installation Guide](https://medium.com/pharos-production/apache-pulsar-macos-installation-guide-f4f67fce1160)
* [Apache Pulsar Using Java](https://medium.com/pharos-production/apache-pulsar-using-java-d2b619c9f0b)
* [Rendezvous Architecture for Data Science in Production](https://towardsdatascience.com/rendezvous-architecture-for-data-science-in-production-79c4d48f12b)
* [Apache Pulsar as One Storage System for Both Real-time and Historical Data Analysis](https://medium.com/streamnative/apache-pulsar-as-one-storage-455222c59017)
* [Pulsar vs. Kafka — Part 1 — A More Accurate Perspective on Performance, Architecture, and Features](https://streamnative.io/blog/tech/pulsar-vs-kafka-part-1)
* [Event-driven railway network based on Pulsar - I'm Pavels, welcome!](https://scala.monster/train-station/) scala
* [Scale By The Bay 2020: Keynote: Karthik Ramasy, Apache Pulsar @ Splunk - YouTube](https://www.youtube.com/watch?v=rmiQb4wsCTI)
* [Event Streaming with Apache Pulsar and Scala - Rock the JVM Blog](https://blog.rockthejvm.com/event-streaming-with-pulsar-and-scala/)

# Ranger
* [Ranger](http://ranger.apache.org)
* [IT’S MORPHING TIME: APACHE RANGER GRADUATES TO A TOP LEVEL PROJECT – PART 2](https://hortonworks.com/blog/morphing-time-apache-ranger-graduates-top-level-project-part-2/)
  * Apache 탑 레벨 프로젝트로 승격된 Apach Ranger에 대한 Key Feature 소개
  * 속성 기반의 엑세스 제어, 정책 엔진, 하드웨어 관리 모들과 결합할 수 있는 키 관리 서비스 등을 포함
* [INTRODUCING ROW/ COLUMN LEVEL ACCESS CONTROL FOR APACHE SPARK](https://hortonworks.com/blog/row-column-level-control-apache-spark/)
  * Hortonworks에서 Apache Ranger를 통해 Hive 또는 Apark SQL에서 행렬 수준의 데이터 엑세스 및 데이터 마스킹을 지원하는 방법을 간단한 데모와 함께 설명
* [Apache Ranger Vs Sentry](https://www.linkedin.com/pulse/apache-ranger-vs-sentry-mythily-rajavelu/) Hadoop 에코시스템들에 대한 인증과 여러 보안 기능을 제공하는 Apache Ranger와 Apache Sentry에 대해 비교 설명

# River
* [River](https://river.apache.org/)

# Samza
* [REAL-TIME FULL-TEXT SEARCH WITH LUWAK AND SAMZA](http://blog.confluent.io/2015/04/13/real-time-full-text-search-with-luwak-and-samza/)
* [Apache Kafka, Samza, and the Unix Philosophy of Distributed Data](http://www.confluent.io/blog/apache-kafka-samza-and-the-unix-philosophy-of-distributed-data)
* [Concourse: Generating Personalized Content Notifications in Near-Real-Time](https://engineering.linkedin.com/blog/2018/05/concourse--generating-personalized-content-notifications-in-near)
  * LinkedIn의 개인화된 알림 시스템인 Concourse의 디자인에 대해 소개
  * Apache Kafka와 Apache Samza에 기반한 배치 시스템을 사용
  * 처리량을 향상시키기 위해 데이터 처리는 각 데이터센터에서 하도록 설계

# SINGA
* [SINGA](http://singa.apache.org/docs/overview.html) a general distributed deep learning platform for training big deep learning models over large datasets

# Slider
* [Slider Project Incubation Status - Apache Incubator](http://incubator.apache.org/projects/slider.html)
* [DEVIEW 2018 :: C3, 데이터 처리에서 서빙까지 가능한 하둡 클러스터](https://deview.kr/2018/schedule/231)
  * [212 C3, 데이터 처리에서 서빙까지 가능한 하둡 클러스터](https://www.slideshare.net/deview/212c3-119161596)

# Solr
* [gooper.com/검색엔진-solr](http://www.gooper.com/ss/index.php?mid=bigdata)

# Spot
* [Spot](http://spot.incubator.apache.org/) 네트워크 데이터를 분석하여 infosec 위협을 탐지하는데 사용
* [Apache Spot (incubating) and Cloudera on AWS in 60 Minutes](http://blog.cloudera.com/blog/2018/02/apache-spot-incubating-and-cloudera-on-aws-in-60-minutes/)
  * Apache Kafka(처리용), Apache Spark(처리 및 ML 분석용), Apache Hadoop(처리 및 저장용) 등을 기반으로 한 Apache Spot의 아키텍처 소개
  * Spot은 파일 시스템의 변경 사항을 감지하고 이벤트를 발생시키는 Python Watchdog 라이브러리를 사용

# Sqoop
* [An HDFS Tutorial for Data Analysts Stuck With Relational Databases](https://www.datatorrent.com/blog/throughput-latency-and-yahoo/) PostgreSQL to HDFS
* [SQOOP으로 MYSQL 데이터 가져오기](https://jungwoon.github.io/jungwoon.github.io/Sqoop-with-MySQL/)
* [How to Convert Apache Sqoop™ Commands Into StreamSets Data Collector Pipelines](https://streamsets.com/blog/using-streamsets-data-collector-modernize-apache-sqoop/)
  * Streamsets의 Dataflow Performance Blog에 올라온 내용
  * Apache Sqoop을 대체하기 위한 마이그레이션 방법 및 고려 사항에 대해 간단하게 설명
* [Using Sqoop to Import Data from MySQL to Cloudera Data Warehouse](https://blog.cloudera.com/blog/2019/02/using-sqoop-to-import-data-from-mysql-to-cloudera-data-warehouse/)
* [An in-depth introduction to SQOOP architecture](https://medium.freecodecamp.org/an-in-depth-introduction-to-sqoop-architecture-ad4ae0532583)

# Storm
* Apache Storm을 이용한 실시간 데이타 처리
  * [데이타 스트림 개념 이해하기](http://bcho.tistory.com/989)
  * [Storm 설치와 HelloStorm 작성하기](http://bcho.tistory.com/991)
  * [Storm 싱글 클러스터 노드 설치 및 배포](http://bcho.tistory.com/993)
  * [Apache Storm 특징과 기본 개념](http://bcho.tistory.com/994)
  * [Apache Storm 병렬 분산 처리 이해하기](http://bcho.tistory.com/995)
  * [Apache Storm 그룹핑 개념 이해하기](http://bcho.tistory.com/997)
* [Scaling Apache Storm - Strata + Hadoop World 2014](http://www.slideshare.net/ptgoetz/scaling-apache-storm-strata-hadoopworld-2014)
* [주니어 개발자의 storm kafka 시작하기](http://blog.embian.com/m/post/108)
* [Real-Time Analytics with Apache Storm](https://www.youtube.com/playlist?list=PLAwxTw4SYaPnWVpbkeoLu7WwI0JIiuXhT)
* [대용량 스트리밍 데이터 실시간 분석](http://d2.naver.com/helloworld/7731491)
* [Reading and Understanding the Storm UI](http://www.malinga.me/reading-and-understanding-the-storm-ui-storm-ui-explained/)
* [Introduction to Apache NiFi and Storm](https://speakerdeck.com/heartsavior/introduction-to-apache-nifi-and-storm)

# Superset
* [Superset](https://github.com/apache/incubator-superset) a data exploration and visualization web application
* [Supercharging Apache Superset | by Airbnb | Airbnb Engineering & Data Science](https://medium.com/airbnb-engineering/supercharging-apache-superset-b1a2393278bd)
* [Use Apache Superset for open source business intelligence reporting | Opensource.com](https://opensource.com/article/21/4/business-intelligence-open-source)

# SystemML
* [SystemML](http://systemml.apache.org/) Apache Spark와 Apache Hadoop을 확장하기 위해 빌드된 machine learning 라이브러리
* [IBM's SystemML Machine Learning - Now Apache SystemML](https://github.com/SparkTC/systemml)
* [The Apache Software Foundation Announces Apache® SystemML™ as a Top-Level Project](https://blogs.apache.org/foundation/entry/the-apache-software-foundation-announces13)

# Tajo
* [Tajo](http://tajo.apache.org/)
* [Introduction to Apache Tajo](http://www.slideshare.net/gruter/introduction-to-apache-tajo)
* [누구나 따라할 수 있는 Tajo 시작하기 : How to install Apache Tajo](http://blrunner.com/101)
* [아즈카반으로 타조 워크플로우 구성하기 : How to schedule Tajo Job using Azkaban](http://blrunner.com/102)
* [Collaborate Apache Tajo + Elasticsearch](https://github.com/gruter/tajo-elasticsearch)
* [아파치 타조(Apache Tajo)를 이용한 코호트(Cohort) 분석](http://blrunner.com/80)
* [아파치 타조 (Apache Tajo) 한글 문서 프로젝트 리소스 및 진행 공유](http://diveintodata.org/2015/01/01/%EC%95%84%ED%8C%8C%EC%B9%98-%ED%83%80%EC%A1%B0-apache-tajo-%ED%95%9C%EA%B8%80-%EB%AC%B8%EC%84%9C-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EB%A6%AC%EC%86%8C%EC%8A%A4-%EB%B0%8F-%EC%A7%84%ED%96%89/)
* [Big data analysis with R and Apache Tajo (in Korean)](http://www.slideshare.net/gruter/ruck2015-gruter-public)
* [Tajo Seoul Meetup July 2015 - What's New Tajo 0.11](http://www.slideshare.net/hyunsikchoi/tajo-meetup-0716)
* [Apache Tajo 데스크탑 + Zeppelin 연동 하기](http://jjeong.tistory.com/1031)
* [Expanding Your Data Warehouse with Tajo](http://www.slideshare.net/blrunner/expanding-your-data-warehouse-with-tajo)
* [AWS + Tajo를 이용한 '테라 렉 로그 분석 이야기'](http://www.slideshare.net/zenos2408/aws-tajo)
* [Python 에서 Tajo 사용하기](http://linewalks.com/archives/1085)
* [MelOn 빅데이터 플랫폼과 Tajo 이야기](http://www.slideshare.net/gruter/melon-tajo)

# Thrift
* [Apache Thrift](https://github.com/likejazz/likejazz.github.io/wiki/Apache-Thrift)
* [아파치 쓰리프트의 bool 타입 관련 제한 값](http://knight76.tistory.com/entry/%EC%95%84%ED%8C%8C%EC%B9%98-%EC%93%B0%EB%A6%AC%ED%94%84%ED%8A%B8%EC%9D%98-bool-%ED%83%80%EC%9E%85-%EA%B4%80%EB%A0%A8-%EC%A0%9C%ED%95%9C-%EA%B0%92)

# Tika
* [Tika](https://tika.apache.org/)

# Toree
* [Toree](http://toree.apache.org/)

# Traffic Server
* [Apache Traffic Server](https://trafficserver.apache.org/)

# UIMA
* [UIMA](https://uima.apache.org)

# WEEX
* [WEEX](https://weex.apache.org/) A framework for building Mobile cross-platform UIs

# Zookeeper
* [Zookeeper](http://zookeeper.apache.org/)
* [Zoom: Reactive Programming with Zookeeper](http://blog.midonet.org/zoom-reactive-programming-zookeeper/)
* [The Discovery of Apache ZooKeeper’s Poison Packet](http://www.pagerduty.com/blog/the-discovery-of-apache-zookeepers-poison-packet/)
* [Mining Zookeeper’s transaction log to track down bugs](https://medium.com/@ivankelly/mining-zookeeper-s-transaction-log-to-track-down-bugs-63b4c653bb6)
* [Apache ZooKeeper Four Letter Words and Security](http://blog.cloudera.com/blog/2017/06/apache-zookeeper-four-letter-words-and-security/)
  * Apache ZooKeeper의 네 글자 단어 지원(4lw)에 대한 간략한 내용
  * 이러한 관리 명령의 경우 정상적인 ZK 포트를 통한 연결과 같이 좋은 보안 솔루션이 없음
  * 다른 방법으로, ZooKeeper는 JMX를 지원하고 3.5.x 릴리스에서는 별도의 포트에 AdminServer를 제공
* [Zookeeper 클러스터 및 컨트롤러 선출 :: 당근케잌](https://yeon-kr.tistory.com/184)
* [consul.io](https://www.consul.io/)
  * [HashiCorp사의 Consul, Consul Template 소개](https://medium.com/giljae/hashicorp%EC%82%AC%EC%9D%98-consul-consul-template-%EC%86%8C%EA%B0%9C-cc0837533fbc)
  * [Real-time Service Configuration으로 Consul을 신주소 서비스에 적용한 사례](http://woowabros.github.io/tools/2018/10/08/location-service-with-rcs.html)
  * [Mitchell Hashimoto on Consul since 1.2 and its Role as a Modern Service Mesh](https://www.youtube.com/watch?v=ZQFzR9JjxiI)
  * [Announcing HashiCorp’s Homebrew Tap](https://www.hashicorp.com/blog/announcing-hashicorp-homebrew-tap)
  * `/usr/bin/consul-template -consul-retry-attempts=1 -template "./dynamic.ctmpl:./dynamic.conf" -config="/etc/consul.d/template/config.json" -once` template에서 conf를 생성하는 예
