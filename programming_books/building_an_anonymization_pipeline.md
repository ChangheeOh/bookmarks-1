# 데이터 익명화를 위한 파이프라인 Building an Anonymization Pipeline
<img src="building_an_anonymization_pipeline/0.jpg" alt="title" width="400"/>

<img src="building_an_anonymization_pipeline/1.jpg" alt="" width="400"/>

> 건강보험 정보의 이전 및 책임에 관한 법률(HIPPA)

<img src="building_an_anonymization_pipeline/2.jpg" alt="" width="400"/>

> 일반 데이터 보호 규정(GDPR)

<img src="building_an_anonymization_pipeline/3.jpg" alt="" width="400"/>

> 표 1-1 미국과 유럽 용어의 유사성에 따른 기본 정의
>
> 표 1-2 다양한 기관의 식별 가능성에 대한 조건

<img src="building_an_anonymization_pipeline/4.jpg" alt="" width="400"/>

> 식별화identification라는 용어는 데이터에 이름이나 주소와 같은 직접 식별되는 정보가 있다는 의미로 사용
>
> 가명화pseudonymization라는 용어는 데이터 보호 메커니즘으로서 단순히 식별자가 어떤 식으로든 제거되었음을 의미
>
> 익명화anonymization는 주어진 데이터 공유 모델에 대한 직접 및 간접 식별자를 제거하여 데이터를 식별할 수 없다는 합리적인 보장을 제공하는 프로세스다.

<img src="building_an_anonymization_pipeline/5.jpg" alt="" width="400"/>

<img src="building_an_anonymization_pipeline/6.jpg" alt="" width="400"/> <img src="building_an_anonymization_pipeline/7.jpg" alt="" width="400"/>

> 신뢰 기반: 정직함 신중함 보호 충성도

<img src="building_an_anonymization_pipeline/8.jpg" alt="" width="400"/>

> 인공지능의 윤리 및 데이터 보호에 관한 선언 벨기에 브뤼셀에서 열린 데이터 보호 및 개인 정보 보호 국제회의(2018년 10월23일)
  * [40th International Conference of Data Protection and Privacy Commissioners, Brussels](https://www.privacyconference2018.org/system/files/2018-10/20180922_ICDPPC-40th_AI-Declaration_ADOPTED.pdf)
> 마이클 빌(Michael Veale), 루벤 빈스(Reuben Binns), 리안 에드워즈(Lilian Edwards)의 기억하는 알고리즘 모델 반전 공격 및 데이터 보호 법률 참조 Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 376, no. 2133 (2018): 20180083
  * [Algorithms that remember: model inversion attacks and data protection law | Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences](https://royalsocietypublishing.org/doi/10.1098/rsta.2018.0083)
> 조지 E.P 박스(George E.P Box)의 과학 모델 구축 전략의 강건성, 통계학의 강건성 등에 고전적인 설명이 제공된다. 로버트 L. 로너(Robert L. Launer), 그레이엄 N. 윌킨슨(Graham N. Wilkinson) 편집 (뉴욕: Academic Press, 1979), 201-236
  * [Robustness in the Strategy of Scientific Model Building - ScienceDirect](https://www.sciencedirect.com/science/article/pii/B9780124381506500182)

<img src="building_an_anonymization_pipeline/9.jpg" alt="" width="400"/> <img src="building_an_anonymization_pipeline/10.jpg" alt="" width="400"/>

> AIML의 기술

<img src="building_an_anonymization_pipeline/11.jpg" alt="" width="400"/> <img src="building_an_anonymization_pipeline/12.jpg" alt="" width="400"/>

> 기술적 과제

<img src="building_an_anonymization_pipeline/13.jpg" alt="" width="400"/> <img src="building_an_anonymization_pipeline/14.jpg" alt="" width="400"/> <img src="building_an_anonymization_pipeline/15.jpg" alt="" width="400"/> <img src="building_an_anonymization_pipeline/16.jpg" alt="" width="400"/>

> 신뢰에 실패한 알고리즘, 악성 챗봇, 범죄 예측

<img src="building_an_anonymization_pipeline/17.jpg" alt="" width="400"/> <img src="building_an_anonymization_pipeline/18.jpg" alt="" width="400"/>

> 책임 있는 AIML의 원칙, 예측 가능, 관리 가능, 분리됨

<img src="building_an_anonymization_pipeline/19.jpg" alt="" width="400"/> <img src="building_an_anonymization_pipeline/20.jpg" alt="" width="400"/> <img src="building_an_anonymization_pipeline/21.jpg" alt="" width="400"/>

> 개인 정보 윤리, 데이터 모니터링